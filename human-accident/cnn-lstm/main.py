import torch  # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch.nn as nn  # ì‹ ê²½ë§ ëª¨ë“ˆ(ë ˆì´ì–´, ì†ì‹¤ í•¨ìˆ˜ ë“±)ì„ í¬í•¨í•˜ëŠ” PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch.optim as optim  # ìµœì í™” ì•Œê³ ë¦¬ì¦˜(Adam, SGD ë“±)ì„ í¬í•¨í•˜ëŠ” PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬
import tensorboardX  # TensorBoard ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (íŒŒì¼ ê²½ë¡œ, ë””ë ‰í† ë¦¬ ìƒì„± ë“±)
import random  # ë‚œìˆ˜ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

from torch.utils.data import DataLoader  # ë°ì´í„°ì…‹ì„ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë¡œë“œí•˜ëŠ” PyTorch ìœ í‹¸ë¦¬í‹°
from torch.optim import lr_scheduler  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìœ„í•œ PyTorch ìœ í‹¸ë¦¬í‹°

from opts import parse_opts  # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±ì„ ìœ„í•œ opts.pyì—ì„œ parse_opts í•¨ìˆ˜ ì„í¬íŠ¸

from train import train_epoch  # í•™ìŠµ ë¡œì§ì´ êµ¬í˜„ëœ train.pyì—ì„œ train_epoch í•¨ìˆ˜ ì„í¬íŠ¸

from validation import val_epoch  # ê²€ì¦ ë¡œì§ì´ êµ¬í˜„ëœ validation.pyì—ì„œ val_epoch í•¨ìˆ˜ ì„í¬íŠ¸

from model import generate_model  # ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìƒì„±í•˜ëŠ” model.pyì—ì„œ generate_model í•¨ìˆ˜ ì„í¬íŠ¸

from dataset import get_training_set, get_validation_set  # ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¤ëŠ” dataset.pyì˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸

from mean import get_mean, get_std  # ë°ì´í„° ì •ê·œí™”ë¥¼ ìœ„í•œ í‰ê· , í‘œì¤€í¸ì°¨ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” mean.pyì˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸



from spatial_transforms import (    # ì´ë¯¸ì§€ í”„ë ˆì„ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜(augmentation) í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
    Compose,                        # ì—¬ëŸ¬ ë³€í™˜ì„ ë¬¶ì–´ì£¼ëŠ” í´ë˜ìŠ¤
    Normalize,                      # í…ì„œë¥¼ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”í•˜ëŠ” í´ë˜ìŠ¤
    Scale,                          # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ëŠ” í´ë˜ìŠ¤
    CenterCrop,                     # ì´ë¯¸ì§€ ì¤‘ì•™ì„ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    CornerCrop,                     # ì´ë¯¸ì§€ ëª¨ì„œë¦¬ë¥¼ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    MultiScaleCornerCrop,           # ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ëª¨ì„œë¦¬ë¥¼ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    MultiScaleRandomCrop,           # ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    RandomHorizontalFlip,           # ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì¢Œìš° ë°˜ì „í•˜ëŠ” í´ë˜ìŠ¤
    ToTensor,                       # PIL ì´ë¯¸ì§€ë‚˜ 'numpy ë°°ì—´'ì„ 'í…ì„œ'ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤
)
from temporal_transforms import LoopPadding, TemporalRandomCrop  # ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ì— ì ìš©í•  ì‹œê°„ì  ë³€í™˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from target_transforms import ClassLabel, VideoID  # íƒ€ê²Ÿ(ë¼ë²¨) ë°ì´í„°ì— ì ìš©í•  ë³€í™˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from target_transforms import Compose as TargetCompose  # íƒ€ê²Ÿ ë³€í™˜ì„ ë¬¶ì–´ì£¼ê¸° ìœ„í•œ Compose í´ë˜ìŠ¤ ì„í¬íŠ¸


def resume_model(opt, model, optimizer):
    """Resume model"""
    checkpoint = torch.load(opt.resume_path)  # ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë“œ
    model.load_state_dict(checkpoint["state_dict"])  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(state_dict)ë¥¼ í˜„ì¬ ëª¨ë¸ì— ë¡œë“œ
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì˜µí‹°ë§ˆì´ì €ì˜ ìƒíƒœ(state_dict)ë¥¼ í˜„ì¬ ì˜µí‹°ë§ˆì´ì €ì— ë¡œë“œ
    print("Model Restored from Epoch {}".format(checkpoint["epoch"]))  # ëª‡ ë²ˆì§¸ ì—í­ì—ì„œ ì €ì¥ëœ ëª¨ë¸ì¸ì§€ ì¶œë ¥
    start_epoch = checkpoint["epoch"] + 1  # ë‹¤ìŒ í•™ìŠµì„ ì‹œì‘í•  ì—í­ ë²ˆí˜¸ ì„¤ì • (ì €ì¥ëœ ì—í­ + 1)
    return start_epoch  # ì‹œì‘í•  ì—í­ ë²ˆí˜¸ ë°˜í™˜


def get_loaders(opt):
    """Make dataloaders for train and validation sets"""
    # train loader
    opt.mean = get_mean(opt.norm_value, dataset=opt.mean_dataset)  # ì •ê·œí™”ì— ì‚¬ìš©í•  í‰ê· ê°’ ê³„ì‚°
    if opt.no_mean_norm and not opt.std_norm:  # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ê·œí™”ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        norm_method = Normalize([0, 0, 0], [1, 1, 1])  # ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ” ê²ƒê³¼ ê°™ì€ íš¨ê³¼ (0ì„ ë¹¼ê³  1ë¡œ ë‚˜ëˆ”)
    elif not opt.std_norm:  # í‰ê·  ì •ê·œí™”ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        norm_method = Normalize(opt.mean, [1, 1, 1])  # í‰ê· ê°’ë§Œ ë¹¼ê³ , 1ë¡œ ë‚˜ëˆ„ì–´ í‘œì¤€í¸ì°¨ ì •ê·œí™”ëŠ” ìƒëµ
    else:  # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ê·œí™”ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        norm_method = Normalize(opt.mean, opt.std)  # í‰ê· ì„ ë¹¼ê³  í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ”
    spatial_transform = Compose(  # í•™ìŠµ ë°ì´í„°ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜ë“¤ì„ ì •ì˜
        [
            # crop_method,
            Scale((opt.sample_size, opt.sample_size)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ (sample_size, sample_size)ë¡œ ì¡°ì ˆ
            # RandomHorizontalFlip(),
            ToTensor(opt.norm_value),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  norm_valueë¡œ ë‚˜ëˆ”
            norm_method,  # ìœ„ì—ì„œ ì •ì˜í•œ ì •ê·œí™” ë°©ë²• ì ìš©
        ]
    )
    temporal_transform = TemporalRandomCrop(16)  # ë¹„ë””ì˜¤ í”„ë ˆì„ ì‹œí€€ìŠ¤ì—ì„œ 16 í”„ë ˆì„ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ëƒ„
    target_transform = ClassLabel()  # íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ ë¼ë²¨ë§Œ ì¶”ì¶œ
    training_data = get_training_set(  # í•™ìŠµ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
        opt, spatial_transform, temporal_transform, target_transform  # ì˜µì…˜ê³¼ ë³€í™˜ë“¤ì„ ì „ë‹¬
    )
    train_loader = torch.utils.data.DataLoader(  # í•™ìŠµ ë°ì´í„° ë¡œë” ìƒì„±
        training_data,  # ìœ„ì—ì„œ ìƒì„±í•œ ë°ì´í„°ì…‹ ê°ì²´
        batch_size=opt.batch_size,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        shuffle=True,  # ì—í­ë§ˆë‹¤ ë°ì´í„°ë¥¼ ì„ì„ì§€ ì—¬ë¶€ (í•™ìŠµ ì‹œì—ëŠ” Trueê°€ ì¼ë°˜ì )
        num_workers=opt.num_workers,  # ë°ì´í„° ë¡œë”©ì— ì‚¬ìš©í•  ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ìˆ˜
        pin_memory=True,  # GPUë¡œ ë°ì´í„°ë¥¼ ë” ë¹¨ë¦¬ ì „ì†¡í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ì— ê³ ì •
    )

    # validation loader
    spatial_transform = Compose(  # ê²€ì¦ ë°ì´í„°ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜ë“¤ì„ ì •ì˜ (ë³´í†µ augmentation ì œì™¸)
        [
            Scale((opt.sample_size, opt.sample_size)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ (sample_size, sample_size)ë¡œ ì¡°ì ˆ
            # CenterCrop(opt.sample_size),
            ToTensor(opt.norm_value),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  norm_valueë¡œ ë‚˜ëˆ”
            norm_method,  # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì •ê·œí™” ë°©ë²• ì ìš©
        ]
    )
    target_transform = ClassLabel()  # íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ ë¼ë²¨ë§Œ ì¶”ì¶œ
    temporal_transform = LoopPadding(16)  # ë¹„ë””ì˜¤ í”„ë ˆì„ ì‹œí€€ìŠ¤ê°€ 16ë³´ë‹¤ ì§§ì„ ê²½ìš°, ì•ë¶€ë¶„ì„ ë°˜ë³µí•´ì„œ 16 í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¦
    validation_data = get_validation_set(  # ê²€ì¦ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
        opt, spatial_transform, temporal_transform, target_transform  # ì˜µì…˜ê³¼ ë³€í™˜ë“¤ì„ ì „ë‹¬
    )
    val_loader = torch.utils.data.DataLoader(  # ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±
        validation_data,  # ìœ„ì—ì„œ ìƒì„±í•œ ë°ì´í„°ì…‹ ê°ì²´
        batch_size=opt.batch_size,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        shuffle=False,  # ê²€ì¦ ì‹œì—ëŠ” ë°ì´í„°ë¥¼ ì„ì§€ ì•ŠìŒ (ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´)
        num_workers=opt.num_workers,  # ë°ì´í„° ë¡œë”©ì— ì‚¬ìš©í•  ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ìˆ˜
        pin_memory=True,  # GPUë¡œ ë°ì´í„°ë¥¼ ë” ë¹¨ë¦¬ ì „ì†¡í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ì— ê³ ì •
    )
    return train_loader, val_loader  # ìƒì„±ëœ í•™ìŠµ ë° ê²€ì¦ ë°ì´í„° ë¡œë” ë°˜í™˜


# 2. main_worker() í•¨ìˆ˜ë¥¼ ë“¤ì—¬ë‹¤ë³´ì~
def main_worker():
    # 3. parsing
    opt = parse_opts()  # ì»¤ë§¨ë“œë¼ì¸ ì¸ìë“¤ì„ íŒŒì‹±í•˜ì—¬ opt ê°ì²´ì— ì €ì¥
    # parser : compilerì˜ ì¼ë¶€ë¡œ ì»´íŒŒì¼ëŸ¬ë‚˜ ì¸í„°í”„ë¦¬í„°ì—ì„œ ì›ì‹œ í”„ë¡œê·¸ë¨ì„ ì½ì–´ ë“¤ì—¬ ê·¸ ë¬¸ì¥ì˜ êµ¬ì¡°ë¥¼ ì•Œì•„ë‚´ëŠ” parsing(êµ¬ë¬¸ ë¶„ì„)ì„ í–‰í•˜ëŠ” í”„ë¡œê·¸ë¨
    # opt = options(ì˜µì…˜ë“¤) ì˜ ì¤„ì„ë§ / ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ë°›ì€ ì„¤ì •ê°’ë“¤ì„ ëª¨ì•„ë‘” ê°ì²´
    print(opt)  # íŒŒì‹±ëœ ì˜µì…˜ë“¤ì„ ì¶œë ¥í•˜ì—¬ í™•ì¸

    # ğŸš¨ 4. ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ(seed) ê³ ì •
    seed = 1  # ì‹œë“œ ê°’ ì„¤ì •
    random.seed(seed)  # íŒŒì´ì¬ ë‚´ì¥ random ëª¨ë“ˆì˜ ì‹œë“œ ê³ ì •
    np.random.seed(seed)  # numpyì˜ ì‹œë“œ ê³ ì •
    torch.manual_seed(seed)  # PyTorchì˜ CPU ì—°ì‚°ì— ëŒ€í•œ ì‹œë“œ ê³ ì •
    # ì´ë ‡ê²Œ ê³ ì •í•˜ëŠ” ì´ìœ  : ë‚´ê°€ ë§Œë“  ëª¨ë¸ì„ ë‹¤ì‹œ ëŒë ¸ì„ ë•Œ, í˜¹ì€ ë‹¤ë¥¸ ì‚¬ëŒì´ ë‚´ ì½”ë“œë¥¼ ëŒë ¸ì„ ë•Œ ê²°ê³¼ê°€ ë˜‘ê°™ì´ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ.

    # 5. CUDA for PyTorch
    device = torch.device(f"cuda:{opt.gpu}" if opt.use_cuda else "cpu")  # --use_cuda ì˜µì…˜ì´ ìˆìœ¼ë©´ ì§€ì •ëœ GPUë¥¼, ì—†ìœ¼ë©´ CPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •

    # tensorboard
    summary_writer = tensorboardX.SummaryWriter(log_dir="tf_logs")  # TensorBoard ë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì • ë° writer ê°ì²´ ìƒì„±

    # defining model
    model = generate_model(opt, device)  # ì„¤ì •(opt)ì— ë§ëŠ” model(model.py íŒŒì¼ ì°¸ì¡°)ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ ì¥ì¹˜(device)ë¡œ ì´ë™
    # get data loaders
    train_loader, val_loader = get_loaders(opt)  # í•™ìŠµ ë° ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±

    # optimizer
    crnn_params = list(model.parameters())  # ìµœì í™”í•  ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´
    optimizer = torch.optim.Adam(  # Adam ì˜µí‹°ë§ˆì´ì € ìƒì„±
        crnn_params, lr=opt.lr_rate, weight_decay=opt.weight_decay  # ëª¨ë¸ íŒŒë¼ë¯¸í„°, í•™ìŠµë¥ , ê°€ì¤‘ì¹˜ ê°ì‡ (L2 ì •ê·œí™”) ì„¤ì •
    )

    # scheduler = lr_scheduler.ReduceLROnPlateau(
    # 	optimizer, 'min', patience=opt.lr_patience)
    criterion = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ CrossEntropy ì†ì‹¤ í•¨ìˆ˜ ì •ì˜

    # resume model
    if opt.resume_path:  # --resume_path ì˜µì…˜ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì£¼ì–´ì§„ ê²½ìš°
        start_epoch = resume_model(opt, model, optimizer)  # ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ë³µì›í•˜ê³  ì‹œì‘ ì—í­ì„ ë°›ì•„ì˜´
    else:  # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì£¼ì–´ì§€ì§€ ì•Šì€ ê²½ìš° (ì²˜ìŒë¶€í„° í•™ìŠµ)
        start_epoch = 1  # 1 ì—í­ë¶€í„° í•™ìŠµ ì‹œì‘

    # start training
    for epoch in range(start_epoch, opt.n_epochs + 1):  # ì‹œì‘ ì—í­ë¶€í„° ë§ˆì§€ë§‰ ì—í­ê¹Œì§€ ë°˜ë³µ
        train_loss, train_acc = train_epoch(  # 1 ì—í­ ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµ
            model, train_loader, criterion, optimizer, epoch, opt.log_interval, device  # í•„ìš”í•œ ëª¨ë“  ê°ì²´ì™€ ì„¤ì •ì„ ì „ë‹¬
        )
        val_loss, val_acc = val_epoch(model, val_loader, criterion, device)  # 1 ì—í­ í•™ìŠµ í›„ ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

        # saving weights to checkpoint
        if (epoch) % opt.save_interval == 0:  # í˜„ì¬ ì—í­ì´ 'save_interval'ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§ˆ ë•Œë§ˆë‹¤
            # scheduler.step(val_loss)
            # write summary
            summary_writer.add_scalar(  # TensorBoardì— í•™ìŠµ ì†ì‹¤ ê¸°ë¡
                "losses/train_loss", train_loss, global_step=epoch  # 'losses/train_loss' íƒœê·¸ë¡œ, í˜„ì¬ ì—í­ì„ xì¶•ìœ¼ë¡œ í•˜ì—¬ ê¸°ë¡
            )
            summary_writer.add_scalar("losses/val_loss", val_loss, global_step=epoch)  # TensorBoardì— ê²€ì¦ ì†ì‹¤ ê¸°ë¡
            summary_writer.add_scalar(  # TensorBoardì— í•™ìŠµ ì •í™•ë„ ê¸°ë¡
                "acc/train_acc", train_acc * 100, global_step=epoch  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ë¡
            )
            summary_writer.add_scalar("acc/val_acc", val_acc * 100, global_step=epoch)  # TensorBoardì— ê²€ì¦ ì •í™•ë„ ê¸°ë¡

            state = {  # ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥í•  ì •ë³´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì„±
                "epoch": epoch,  # í˜„ì¬ ì—í­ ë²ˆí˜¸
                "state_dict": model.state_dict(),  # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
                "optimizer_state_dict": optimizer.state_dict(),  # ì˜µí‹°ë§ˆì´ì €ì˜ ìƒíƒœ
            }
            torch.save(  # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì €ì¥
                state,  # ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
                os.path.join(  # ì €ì¥ ê²½ë¡œì™€ íŒŒì¼ ì´ë¦„ ìƒì„±
                    "snapshots", f"{opt.model}-Epoch-{epoch}-Loss-{val_loss:.4f}.pth"  # snapshots í´ë”ì— ëª¨ë¸, ì—í­, ì†ì‹¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì´ë¦„ìœ¼ë¡œ ì €ì¥
                ),
            )
            print("Epoch {} model saved!\n".format(epoch))  # ëª¨ë¸ ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥


if __name__ == "__main__":
    # 1. main_worker í•¨ìˆ˜ê°€ ìµœì´ˆ ì‹œì‘ì§€ì ì…ë‹ˆë‹¤.
    main_worker()  # ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main_worker í•¨ìˆ˜ í˜¸ì¶œ
