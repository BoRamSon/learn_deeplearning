{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd692c70",
   "metadata": {},
   "source": [
    "# 🟩 Model Selection & Design  \n",
    "\n",
    "### ❤️ 지금까지 해온 것 정리하기  \n",
    "1. 처음 목표를 정했다. = **산업안전**  \n",
    "\n",
    "2. 관련 데이터셋을 찾았다. = **스마트 제조 시설 안전 감시를 위한 데이터**  \n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=1&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%A0%9C%EC%A1%B0&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&aihubDataSe=data&dataSetSn=71679  \n",
    "\n",
    "3. 데이터셋을 어떤 `모델`로 학습할 것인지 정했다. = **cnn-lstm**  \n",
    "    - https://github.com/pranoyr/cnn-lstm  \n",
    "\n",
    "4. 해당 모델이 학습할 수 있는 형태로 데이터셋을 **`전처리`** 해준다.  \n",
    "    - https://github.com/pranoyr/cnn-lstm/blob/master/dataset.py  \n",
    "\n",
    "5. https://github.com/pranoyr/cnn-lstm/blob/master/dataset.py 코드 파악 완료  \n",
    "\n",
    "6. 이제 모델을 활용해 학습을 해야한다!!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112478a",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 🟩 Model Training  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485a09f",
   "metadata": {},
   "source": [
    "## 🟢 본격적으로 training 들어가기  \n",
    "1. 나는 제조업에서 발생하는 안전사고를 사전에 차단하기 위해 컴퓨터 비전 기술을 개발하려고 합니다.  \n",
    "    - 개발환경  \n",
    "        - Desktop (NVIDIA GeForce GTX 1650)  \n",
    "        - astral uv packag 관리자 사용중  \n",
    "            - 현재 설치된 라이브러리 (현재 다 설치되어 있음.)  \n",
    "                - [project]  \n",
    "                    version = \"0.1.0\"  \n",
    "                    readme = \"README.md\"  \n",
    "                    requires-python = \">=3.11\"  \n",
    "\n",
    "                    dependencies = [  \n",
    "                        \"matplotlib>=3.10.6\",  \n",
    "                        \"numpy>=2.3.2\",  \n",
    "                        \"torch\",  \n",
    "                        \"torchvision\",  \n",
    "                        \"torchaudio\",  \n",
    "                        \"python-dotenv>=1.1.1\",  \n",
    "                        \"opencv-python>=4.11.0.86\",  \n",
    "                        \"tensorflow>=2.20.0\",  \n",
    "                        \"nbconvert>=7.16.6\",  \n",
    "                        \"nbformat>=5.10.4\",  \n",
    "                        \"seaborn>=0.13.2\",  \n",
    "                    ]  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-cu128\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cu128\"  \n",
    "                    explicit = true  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-cpu\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cpu\"  \n",
    "                    explicit = true  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-mps\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cpu\"  \n",
    "                    explicit = true  \n",
    "\n",
    "\n",
    "                    [tool.uv.sources]  \n",
    "                    torch = [  \n",
    "                        # Windows/Linux → CUDA 12.8 wheel 인덱스  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        # macOS → CPU wheel (MPS 지원 포함)  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "                    torchvision = [  \n",
    "                        # torchvision도 torch와 동일한 인덱스를 사용하도록 설정  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "                    torchaudio = [  \n",
    "                        # torchaudio도 torch와 동일한 인덱스를 사용하도록 설정  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "\n",
    "<br>\n",
    "\n",
    "2. AI허브 데이터셋 = 스마트 제조 시설 안전 감시를 위한 데이터  \n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=1&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%A0%9C%EC%A1%B0&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&aihubDataSe=data&dataSetSn=71679  \n",
    "    - 위 데이터셋을 가지고 전처리를 하였으며,  \n",
    "    - 여기까지 코드를 만들었어요~  \n",
    "        ```python\n",
    "            from torch.utils.data import DataLoader  # 데이터로더를 만들기 위함  \n",
    "\n",
    "            # 이미지에 대한 경로, 일괄적으로 적용할 전처리 이 2가지를 인수로 넣어줌.  \n",
    "            dataset = CustomData(video_path, transform)  \n",
    "\n",
    "\n",
    "            dataloader = DataLoader(  \n",
    "                dataset=dataset,  \n",
    "                batch_size=8,  # 컴퓨터사양에 따라서 메모리가 처리할 수 있는 양을 정해줘야합니다.  \n",
    "                # 2n승 으로 늘려주는 편이다. 2,4,8,16,32,64,128,~~256,  \n",
    "                # 정해주고, 메모리가 감당이 가능한지 확인해봐야합니다.  \n",
    "                shuffle=True,  \n",
    "                drop_last=False,  # 마지막에 남는 데이터도 사용합니다. (False: 버리지 않음)  \n",
    "            )  \n",
    "        ```\n",
    "\n",
    "<br>\n",
    "\n",
    "3. 내가 사용할 모델 https://github.com/pranoyr/cnn-lstm 에 대한 코드 파악을 하고, 나의 폴더 내에 통째로 clone을 해둔 상태입니다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "4. 현재 폴더 구조 정보  \n",
    "    .venv  \n",
    "    pyproject.toml  \n",
    "    uv.lock  \n",
    "    human-accident/  \n",
    "    ├── data  \n",
    "    │   ├── safety-data             \n",
    "    │   │   └── human-accident      # AI허브에서 다운로드하여 전처리한 데이터  \n",
    "    ├── cnn-lstm/                   # pranoyr/cnn-lstm 저장소 clone  \n",
    "    │   ├── datasets/  \n",
    "    │   │   └── ucf101.py           # UCF101 데이터셋 로직 정의  \n",
    "    │   ├── models/  \n",
    "    │   │   └── cnnlstm.py          # CNN-LSTM 모델 아키텍처 정의  \n",
    "    │   ├── main.py                 # 전체 학습 파이프라인 실행  \n",
    "    │   ├── opts.py                 # 커맨드라인 옵션 정의  \n",
    "    │   ├── dataset.py              # 데이터셋 선택 및 생성  \n",
    "    │   ├── model.py                # 모델 선택 및 생성  \n",
    "    │   ├── train.py                # 1 에폭(epoch) 학습 로직  \n",
    "    │   ├── validation.py           # 1 에폭(epoch) 검증 로직  \n",
    "    │   ├── mean.py                 # 데이터 정규화를 위한 평균값 계산  \n",
    "    │   ├── spatial_transforms.py   # 공간적 데이터 증강/변환  \n",
    "    │   ├── temporal_transforms.py  # 시간적 데이터 증강/변환  \n",
    "    │   ├── target_transforms.py    # 라벨 데이터 변환  \n",
    "    │   └── utils.py                # 유틸리티 함수  \n",
    "\n",
    "<br>\n",
    "\n",
    "5. 저는 이제 해당 모델을 가지고 학습을 시키려고 하는데 어떻게 시키는 것인지 모릅니다... 저의 프로젝트 폴더 자체를 모두 읽고, 아주 상세하고 자세하게 차근차근 하나하나 알려주면서 진행해주세요!!  \n",
    "\n",
    "\n",
    "6. 모든 내용은 한국어로 진행합니다. 그리고 진행한 상황들은 모두 단계별로 Record_과정 폴더 내에 markdown 파일을 만들어서 기록해주세요!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeea73c",
   "metadata": {},
   "source": [
    "## 🟢 진행  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c17b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Linux / WSL / Windows PowerShell(인스톨된 경우)) 확인\n",
    "# nvidia-smi\n",
    "\n",
    "# FFmpeg (비디오 → 프레임 변환에 필요)\n",
    "# winget install ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414aaf3",
   "metadata": {},
   "source": [
    "## 🟢 생각보다 할 것 없는 것 같아보이는 제시 내용들  \n",
    "\n",
    "- 비디오 → 프레임 변환(스크립트 제공)  →  data/image_data/, data/annotation/mydata.json 준비  \n",
    "\n",
    "- uv run python main.py --use_cuda --gpu 0 ...로 학습 시작(먼저 작게 돌려보기).  \n",
    "\n",
    "- TensorBoard로 모니터링, snapshots/에 체크포인트 저장.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ae326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
