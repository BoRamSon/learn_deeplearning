{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZJURQGFTtFO"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŸ¢ 3.6. ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QukVP25DdqaM"
   },
   "source": [
    "**[ë…¸íŠ¸]**  \n",
    "*ì´ë²ˆ ì¥ì˜ ì½”ë“œëŠ” ì±… ë³¸ë¬¸ì´ë‚˜ ê¹ƒí—ˆë¸Œ ì˜ˆì œ ì†ŒìŠ¤ì™€ ì‚´ì§ ë‹¤ë¦…ë‹ˆë‹¤. ì±…ì—ì„œëŠ” ë¡œì»¬ì— ìˆëŠ” MNIST ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ë„ë¡ ì‘ì„±ë˜ì–´ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” í…ì„œí”Œë¡œ(ì¼€ë¼ìŠ¤)ì˜ mnist ëª¨ë“ˆì„ ì´ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ì½ì–´ ì˜µë‹ˆë‹¤. í° ì°¨ì´ê°€ ì—†ë„ë¡ ìµœëŒ€í•œ ë°‘ë‹¨ì˜ ì½”ë“œë§Œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipì²˜ëŸ¼ í…ì„œí”Œë¡œìš°ë„ ì„¤ì¹˜\n",
    "    - uv pip install tensorflow\n",
    "- GPU ë²„ì „ì„ ì›í•œë‹¤ë©´\n",
    "    - uv pip install tensorflow[and-cuda]\n",
    "\n",
    "- Mac í™˜ê²½ì˜ ê²½ìš°,\n",
    "    - uv pip install tensorflow-macos\n",
    "    - uv pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0RDeGDgFwQL"
   },
   "source": [
    "***dataset/mnist.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dy6qUHP7U6cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 01:11:03.514514: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-04 01:11:03.636019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Bad pipe message: %s [b' 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Sa']\n",
      "Bad pipe message: %s [b'ri/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/', b'ng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nAccept-Encoding: gzip, deflate, br, zstd\\r\\nA']\n",
      "Bad pipe message: %s [b'ept-Language: ko,en-US;q=0.9,en;q=0.8\\r\\nPriority: u=0, i\\r\\nReferer: https://studio.firebase.google.c', b'/\\r\\nSec-Ch-Ua: \"Not;A=Brand\";v=\"99\", \"Google Chrome\";v=\"139\", \"Chromium\";v=\"139\"\\r\\nSec-Ch-Ua-Arch: \"x86\"\\r\\nSec-Ch', b'a-Bitness: \"64\"\\r\\nSec-Ch-Ua-Form-Factors: \"De', b'top\"\\r\\nSec-Ch-Ua-Full-Version: \"139.0.7258.155\"\\r\\nSec-Ch-Ua-Full-Version-List: \"Not;A=Brand\";v=\"99.0.0.0\", \"Google C', b'ome\";v=\"139.0.7258.155\", \"Chromium\";v=\"139.0.7258.155\"\\r\\nSec-Ch-Ua-Mobile: ?0\\r\\nSec-Ch-Ua-Model: \"\"\\r\\nSec-']\n",
      "Bad pipe message: %s [b'-Ua-Platform: \"Windows\"\\r\\nSec-Ch-Ua-Platform-Version: \"15.0.0\"\\r\\nSec']\n",
      "Bad pipe message: %s [b'h-Ua-Wow64: ?0\\r\\nSec-Fetch-Dest: iframe\\r\\nSec-', b'tch-Mode: navigate\\r\\nSec-Fetch-Site: cross-site\\r\\nSec-Fetch-Storage-Acc', b's: none\\r\\nSec-Fetch-User: ?1\\r\\nSec-User-Ip: 10.20.20.208\\r\\nUpgrade-Insecure-Requests: 1\\r\\nX-Forwarded-Ho', b': 43067-firebase-learndeeplearning-1756700868379.cluster-bg6uurscprhn6qxr6xwtrhvkf6.cloudworkstations.dev\\r\\nX-Goog-']\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/learn_deeplearning/.venv/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "2025-09-04 01:11:22.218379: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "save_file = os.getcwd() + \"/mnist.pkl\"\n",
    "\n",
    "\n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë°ì´í„° í‰íƒ„í™”\n",
    "    dataset[\"train_img\"] = train_images.reshape(train_images.shape[0], -1)\n",
    "    dataset[\"train_label\"] = train_labels\n",
    "    dataset[\"test_img\"] = test_images.reshape(test_images.shape[0], -1)\n",
    "    dataset[\"test_label\"] = test_labels\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def init_mnist():\n",
    "    dataset = _convert_numpy()\n",
    "    print(\"Creating pickle file ...\")\n",
    "    with open(save_file, \"wb\") as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def _change_one_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNIST ë°ì´í„°ì…‹ ì½ê¸°\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : ì´ë¯¸ì§€ì˜ í”½ì…€ ê°’ì„ 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™”í• ì§€ ì •í•œë‹¤.\n",
    "    one_hot_label :\n",
    "        one_hot_labelì´ Trueë©´ã€ë ˆì´ë¸”ì„ ì›-í•«(one-hot) ë°°ì—´ë¡œ ëŒë ¤ì¤€ë‹¤.\n",
    "        one-hot ë°°ì—´ì€ ì˜ˆë¥¼ ë“¤ì–´ [0,0,1,0,0,0,0,0,0,0]ì²˜ëŸ¼ í•œ ì›ì†Œë§Œ 1ì¸ ë°°ì—´ì´ë‹¤.\n",
    "    flatten : ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ ë§Œë“¤ì§€ë¥¼ ì •í•œë‹¤.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (í›ˆë ¨ ì´ë¯¸ì§€, í›ˆë ¨ ë ˆì´ë¸”), (ì‹œí—˜ ì´ë¯¸ì§€, ì‹œí—˜ ë ˆì´ë¸”)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "\n",
    "    with open(save_file, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    if normalize:\n",
    "        for key in (\"train_img\", \"test_img\"):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset[\"train_label\"] = _change_one_hot_label(dataset[\"train_label\"])\n",
    "        dataset[\"test_label\"] = _change_one_hot_label(dataset[\"test_label\"])\n",
    "\n",
    "    if not flatten:\n",
    "        for key in (\"train_img\", \"test_img\"):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset[\"train_img\"], dataset[\"train_label\"]), (\n",
    "        dataset[\"test_img\"],\n",
    "        dataset[\"test_label\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGBIQScbTwLc"
   },
   "source": [
    "### 3.6.1 MNIST ë°ì´í„°ì…‹  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "to1hTfy6TzuZ",
    "outputId": "69aa76d3-0176-40df-f7e6-0ea93045ac64"
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X8HGBeVigND"
   },
   "source": [
    "***ch03/mnist_show.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "BpWTXDsjZoHB",
    "outputId": "d76ceaf2-2e8a-4f10-cc69-af2d94418d57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)  # 5\n",
    "\n",
    "print(img.shape)  # (784,)\n",
    "img = img.reshape(28, 28)  # í˜•ìƒì„ ì›ë˜ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¡œ ë³€í˜•\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPmdwb0ykMVu"
   },
   "source": [
    "### 3.6.2 ì‹ ê²½ë§ì˜ ì¶”ë¡  ì²˜ë¦¬  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWgY3H353Tky"
   },
   "source": [
    "***common/functions.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2oIeap2ogMP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)  # ì˜¤ë²„í”Œë¡œ ëŒ€ì±…\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvoxx3Phl3ei"
   },
   "source": [
    "***ch03/neuralnet_mnist.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_zhULlzkRHe",
    "outputId": "7b817eee-c58f-4169-9576-8b9c4a9d5bb6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "        normalize=True, flatten=True, one_hot_label=False\n",
    "    )\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    url = \"https://github.com/WegraLee/deep-learning-from-scratch/raw/refs/heads/master/ch03/sample_weight.pkl\"\n",
    "    urllib.request.urlretrieve(url, \"sample_weight.pkl\")\n",
    "\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "    b1, b2, b3 = network[\"b1\"], network[\"b2\"], network[\"b3\"]\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)  # í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ì›ì†Œì˜ ì¸ë±ìŠ¤ë¥¼ ì–»ëŠ”ë‹¤.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USOnL91bok3H"
   },
   "source": [
    "### 3.6.3 ë°°ì¹˜ ì²˜ë¦¬  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-tsffn4onYv",
    "outputId": "b2efcda2-39fb-4922-aa22-3eef3e06a509"
   },
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUh1HyuRo0cm",
    "outputId": "f9870ee2-42fb-46a3-ab64-0bf284ab7bd3"
   },
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POsMmxaho4H3",
    "outputId": "31a59718-7936-4b00-9eaa-fa767a8bebc7"
   },
   "outputs": [],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjB9dlRwo6xQ",
    "outputId": "a51cdf79-dacc-44a6-aa38-6b750cb04444"
   },
   "outputs": [],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT0Q0VQjo8hg",
    "outputId": "f4f15a1a-82fa-4de6-c4a8-5176dfe7e098"
   },
   "outputs": [],
   "source": [
    "W3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KNLEhlTpAvl"
   },
   "source": [
    "***ch03/neuralnet_mnist_batch.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ii_62OD1pD3i",
    "outputId": "57ea6164-39d2-41ed-e45e-ed2e72386492"
   },
   "outputs": [],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100  # ë°°ì¹˜ í¬ê¸°\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i : i + batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i : i + batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQNmsQqn3p4w",
    "outputId": "e8f319f5-1a28-4b44-fe8d-dcac16f32d0e"
   },
   "outputs": [],
   "source": [
    "list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7li9XlvE3tiZ",
    "outputId": "2dae760b-5070-404f-ed08-7659592ddeef"
   },
   "outputs": [],
   "source": [
    "list(range(0, 10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vas6pnYz3x0L",
    "outputId": "c200fae7-38dd-4ed2-f904-46e3efc7575c"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
    "y = np.argmax(x, axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dd2D3vkI4FuI",
    "outputId": "2b0185a2-6a2a-44ea-dbd6-1de3ddd9cf44"
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 2, 1, 0])\n",
    "t = np.array([1, 2, 0, 0])\n",
    "print(y == t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmA2l0Di4N8C",
    "outputId": "c31acadc-10bb-477d-9795-a5728150c717"
   },
   "outputs": [],
   "source": [
    "np.sum(y == t)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
