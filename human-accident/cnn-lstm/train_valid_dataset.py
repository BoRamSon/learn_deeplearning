from torch.utils.data import Dataset  # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ë§Œë“¤ê¸° ìœ„í•¨
import os
import cv2
import numpy as np
import torch
import random
from typing import List, Tuple


class CustomData(Dataset):
    """
    ë£¨íŠ¸ ê²½ë¡œ(root) ì•„ë˜ í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³ ,
    í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ 70:30(ê¸°ë³¸) ë¹„ìœ¨ë¡œ train/validë¥¼ ë¶„í• í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹.

    ì˜ˆì‹œ ë””ë ‰í† ë¦¬ êµ¬ì¡°:
        root/
            bump/
                abc.avi
                    def.mp4
                        fall-down/
            . . .
        ... (ì´ 6ê°œ í´ë˜ìŠ¤ í´ë”)
    """

    # ===========================================================================
    def __init__(
        self,
        root: str,  # âŒ ì´ê±°ëŠ” listê°€ ì•„ë‹™ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë‹¨ìˆœ string root ê²½ë¡œë§Œ ë“¤ì–´ì˜µë‹ˆë‹¤.
                    # âŒ ê·¸ë ‡ë‹¤ë©´... ë‚˜ì˜ ê°€ê³µëœ ì˜ìƒ path listëŠ” ì–´ë”” ê°€ëŠ”ê±°ì§€??
        transform,
        split: str = "train",  # "train" ë˜ëŠ” "valid" (ê¸°ë³¸ì ìœ¼ë¡œ train)
        train_ratio: float = 0.7,  # train/valid ë¶„í•  ë¹„ìœ¨ (ê¸°ë³¸ì ìœ¼ë¡œ 70:30)
        seed: int = 42,  # ì…”í”Œ ì‹œë“œ (ê¸°ë³¸ì ìœ¼ë¡œ 42)
    ):
        """
            # ìœ„ ë§¤ê°œë³€ìˆ˜ë“¤ì„ ë‹¤ë¥¸ ê³³ì—ì„œ ì‚¬ìš©í•  ë•Œì˜ ì˜ˆì‹œ

                # CustomData ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (train, valid ê°ê° ìƒì„±)
                train_ds = CustomData(root=root, transform=transform, split="train", train_ratio=0.7, seed=42)
                valid_ds = CustomData(root=root, transform=transform, split="valid", train_ratio=0.7, seed=42)

                # DataLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (train, valid ê°ê° ìƒì„±)
                train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2, drop_last=False)
                valid_loader = DataLoader(valid_ds, batch_size=8, shuffle=False, num_workers=2, drop_last=False)
        """

        # ì…ë ¥ ì¸ì ì €ì¥
        self.root = root
        self.transform = transform
        self.split = split
        self.train_ratio = train_ratio
        self.seed = seed

        # ê³ ì • ì‹œí€€ìŠ¤ ê¸¸ì´(ì˜ˆ: 16 í”„ë ˆì„)
            # - ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ìƒ˜í”Œë§ˆë‹¤ ë‹¤ë¥´ë©´ DataLoaderê°€ ë°°ì¹˜ë¥¼ ë§Œë“¤ ë•Œ í…ì„œ í¬ê¸°ê°€ ë§ì§€ ì•Šì•„ ì˜¤ë¥˜ê°€ ë‚©ë‹ˆë‹¤.
            # - ë”°ë¼ì„œ 'ìë¥´ê±°ë‚˜(ìƒ˜í”Œë§) / ëŠ˜ë¦¬ê±°ë‚˜(íŒ¨ë”©)' í•´ì„œ ê¸¸ì´ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶¥ë‹ˆë‹¤.
        self.fixed_len = 16  # DataLoader ë°°ì¹­ì„ ìœ„í•´ í”„ë ˆì„ ê¸¸ì´ë¥¼ ê³ ì •í•©ë‹ˆë‹¤.

        # í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤ ëª©ë¡(í´ë”ëª…ê³¼ ë™ì¼í•´ì•¼ í•¨)
        self.class_names: List[str] = [
            "bump",
            "fall-down",
            "fall-off",
            "hit",
            "jam",
            "no-accident",
        ]

        # ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ í™•ì¥ì
        self.allowed_exts = (".avi", ".mp4", ".mov", ".mkv", ".wmv")

        # --------------------------------------------------
        # 1) ë£¨íŠ¸ ì•„ë˜ í´ë˜ìŠ¤ í´ë”ë¥¼ ìˆœíšŒí•˜ì—¬ í´ë˜ìŠ¤ë³„ ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        #   ğŸ”¥ ì—¬ê¸°ì„œ ì§€ê¸ˆ í´ë˜ìŠ¤ë³„ë¡œ ì˜ìƒ ê²½ë¡œë¥¼ ì¡°íšŒí•´ì„œ í´ë˜ìŠ¤ë³„ ì˜ìƒì„ valueë¡œ ê°€ì§„ dictionaryë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.
        #       ì¦‰ ë‚´ê°€ ê°€ê³µí–ˆë˜ listê°€ ì•„ë‹Œ ì—¬ê¸°ì„œëŠ” dictionaryë¡œ í•©ë‹ˆë‹¤....
        
        class_to_videos = {}

        for cname in self.class_names:
            cdir = os.path.join(self.root, cname)
            if not os.path.isdir(cdir):
                print(f"[ê²½ê³ ] í´ë˜ìŠ¤ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {cdir}")
                class_to_videos[cname] = []
                continue
            vids = [
                os.path.join(cdir, fn)
                for fn in os.listdir(cdir)
                if fn.lower().endswith(self.allowed_exts)
            ]
            vids.sort()
            class_to_videos[cname] = vids

        # --------------------------------------------------
        # 2) í´ë˜ìŠ¤ë³„ë¡œ ì…”í”Œ í›„ train/valid ë¶„í• (ì¬í˜„ì„± ë³´ì¥)
        #   ğŸ”¥ ì—¬ê¸°ì„œ ì˜ìƒì„ train/validë¡œ ë¶„í• í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì´ ì˜ìƒ pathë“¤ì„ train/validë¡œ ë¶„í• í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        rng = random.Random(self.seed)

        self.samples: List[Tuple[str, int]] = []  # train or validì˜ ë¹„ë””ì˜¤ ê²½ë¡œ(str), ë¼ë²¨ ì¸ë±ìŠ¤(int)(í´ë˜ìŠ¤ì˜ indexì…ë‹ˆë‹¤.)

        for idx, cname in enumerate(self.class_names):  # index ë²ˆí˜¸ì™€ í•¨ê»˜ í´ë˜ìŠ¤ë³„ë¡œ 1ê°œì”© ë°›ìŠµë‹ˆë‹¤.
            vids = class_to_videos.get(cname, [])       # í´ë˜ìŠ¤ë³„ë¡œ ì˜ìƒ pathë¥¼ listë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            if not vids:
                continue
            vids_copy = vids[:] # êµ³ì´ ì „ì²´ë¥¼ ëª¨ë‘ ë³µì‚¬í•©ë‹ˆë‹¤.
            rng.shuffle(vids_copy)  # ë³µì‚¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…”í”Œí•©ë‹ˆë‹¤.
            n_total = len(vids_copy)    # ì´ ì˜ìƒ ìˆ˜
            n_train = int(round(n_total * self.train_ratio))    # train/valid ë¶„í•  ë¹„ìœ¨ì— ë”°ë¼ train ì˜ìƒ ìˆ˜
            train_list = vids_copy[:n_train]    # train ì˜ìƒ path list (ì´ëŸ° ì‹ìœ¼ë¡œ ë¶„í• ì„ í•˜ëŠ” ë°©ë²•ì„ ì˜ ìµí˜€ë‘ì„¸ìš”.)
            valid_list = vids_copy[n_train:]    # valid ì˜ìƒ path list (ì´ëŸ° ì‹ìœ¼ë¡œ ë¶„í• ì„ í•˜ëŠ” ë°©ë²•ì„ ì˜ ìµí˜€ë‘ì„¸ìš”.)

            if self.split == "train":   # split ì¸ìˆ˜ê°€ trainì´ë¼ë©´,
                for vp in train_list:
                    self.samples.append((vp, idx))
            elif self.split == "valid": # split ì¸ìˆ˜ê°€ validë¼ë©´,
                for vp in valid_list:
                    self.samples.append((vp, idx))
            else:
                raise ValueError("splitì€ 'train' ë˜ëŠ” 'valid'ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")


    # ===========================================================================
    def __len__(self):
        # ì „ì²´ ìƒ˜í”Œ ìˆ˜ ë°˜í™˜
        return len(self.samples)

    
    # ===========================================================================
    def same_fps(self, path):  # í•˜ë‚˜ì˜ ë™ì˜ìƒ ê²½ë¡œë§Œ ë“¤ì–´ê°€ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        ì…ë ¥ ë¹„ë””ì˜¤ì˜ FPSë¥¼ ê¸°ì¤€ FPS(ì—¬ê¸°ì„œëŠ” 30fps)ì— ë§ì¶°ì„œ í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
        - original_fps > 30  : í”„ë ˆì„ì„ ê±´ë„ˆë›°ë©´ì„œ ë‹¤ìš´ìƒ˜í”Œë§
        - original_fps < 30  : ì¼ë¶€ í”„ë ˆì„ì„ ë³µì œí•˜ì—¬ ì—…ìƒ˜í”Œë§
        - original_fps == 30 : ê·¸ëŒ€ë¡œ ì‚¬ìš©

        ë°˜í™˜ í˜•íƒœ: numpy.ndarray, shape = (T, H, W, C), BGR(Channel ë§ˆì§€ë§‰)
        ì£¼ì˜: OpenCV(cv2)ëŠ” ê¸°ë³¸ BGR ìˆœì„œì…ë‹ˆë‹¤. í•™ìŠµ ì „ì²˜ë¦¬ì—ì„œëŠ” RGBë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        video = cv2.VideoCapture(path)
        if not video.isOpened():
            print("Could not Open :", path)
            return None

        target_fps = 30

        original_fps = int(video.get(cv2.CAP_PROP_FPS))
        # ë””ë²„ê¹…ìš© ë¡œê·¸: ì›ë³¸ FPS
        print(f"í˜„ì¬ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ : {original_fps}")

        frame_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
        # ë””ë²„ê¹…ìš© ë¡œê·¸: ì´ í”„ë ˆì„ ìˆ˜
        print(f"í˜„ì¬ ì´ í”„ë ˆì„ ìˆ˜ : {frame_length}")

        frames = []
        count = 0

        while True:
            ret, img = video.read()  # í•œ í”„ë ˆì„ ì½ê¸°
            if not ret:  # ë” ì´ìƒ í”„ë ˆì„ ì—†ìœ¼ë©´ ì¢…ë£Œ
                break

            if original_fps > target_fps:
                # ì›ë³¸ FPSê°€ ë†’ìœ¼ë©´ ì¼ì • ê°„ê²©(step)ìœ¼ë¡œ í”„ë ˆì„ì„ ì„ íƒí•˜ì—¬ ë‹¤ìš´ìƒ˜í”Œë§
                step = round(original_fps / target_fps)
                if count % step == 0:
                    frames.append(img)
            elif original_fps < target_fps:
                # ì›ë³¸ FPSê°€ ë‚®ìœ¼ë©´ í˜„ì¬ í”„ë ˆì„ì„ ì¶”ê°€í•˜ê³ ,
                # í•œ ì´ˆê°€ ì§€ë‚  ë•Œë§ˆë‹¤(ì›ë³¸ fpsë§ˆë‹¤) ë§ˆì§€ë§‰ í”„ë ˆì„ì„ í•œ ë²ˆ ë” ì¶”ê°€í•˜ì—¬ ì—…ìƒ˜í”Œë§
                frames.append(img)
                if (count + 1) % original_fps == 0:
                    frames.append(img)
            else:
                frames.append(img)

            count += 1  # ì½ì€ í”„ë ˆì„ ìˆ˜ ì¦ê°€

        video.release()

        # numpy ë°°ì—´ë¡œ ë³€í™˜: (T, H, W, C), BGR
        return np.array(frames)


    # ===========================================================================
    # í…ì„œ í˜•íƒœë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ëŒë ¤ì¤Œ
    def __getitem__(self, idx):
        """
        ëª©ì :
            í•˜ë‚˜ì˜ ë¹„ë””ì˜¤ë¥¼ ëª¨ë¸ ì…ë ¥ì— ì í•©í•œ ì‹œí€€ìŠ¤ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - FPSë¥¼ 30ìœ¼ë¡œ ë§ì¶° ì‹œê°„ í•´ìƒë„ë¥¼ í‘œì¤€í™”í•˜ê³ ,
            - ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ self.fixed_len(ì˜ˆ: 16 í”„ë ˆì„)ìœ¼ë¡œ ê³ ì •í•œ ë’¤,
            - í”„ë ˆì„ë³„ ì „ì²˜ë¦¬(Resize/Normalize ë“±)ë¥¼ ì ìš©í•˜ì—¬
            - (T, C, H, W) í˜•íƒœì˜ í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        ì…ë ¥(ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì†ŒìŠ¤):
            - self.samples[idx]ì—ì„œ (video_path, label_index)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            - video_pathëŠ” ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ, label_indexëŠ” í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.

        ì²˜ë¦¬ ë‹¨ê³„(ìš”ì•½):
            1) ë¹„ë””ì˜¤ ë¡œë“œ ë° FPS 30ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
               - same_fps(video_path) -> numpy (T, H, W, C), BGR
            2) ì˜ˆì™¸ ì²˜ë¦¬
               - í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ë”ë¯¸(ê²€ì€ í™”ë©´) í”„ë ˆì„ì„ ìƒì„±í•˜ì—¬ ê¸¸ì´ë¥¼ self.fixed_lenìœ¼ë¡œ ì±„ì›€
            3) ê¸¸ì´ ê³ ì •
               - ê¸¸ë©´ ê· ë“± ìƒ˜í”Œë§ìœ¼ë¡œ self.fixed_lenê°œ ì„ íƒ
               - ì§§ìœ¼ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜ë³µ íŒ¨ë”©ìœ¼ë¡œ ê¸¸ì´ í™•ì¥
            4) í”„ë ˆì„ë³„ ì „ì²˜ë¦¬
               - BGR -> RGB ë³€í™˜ í›„, transform ì ìš©
               - ê¶Œì¥ transform: ToPILImage -> Resize(224,224) -> ToTensor -> Normalize
            5) ì‹œí€€ìŠ¤ í…ì„œ ìƒì„±
               - torch.stackìœ¼ë¡œ (T, C, H, W) í…ì„œ êµ¬ì„±

        ì¶œë ¥(ë°˜í™˜ ê°’):
            - result: torch.FloatTensor, shape=(T, C, H, W)
                ì˜ˆ: T=16, C=3, H=224, W=224
            - label : int (í´ë˜ìŠ¤ ì¸ë±ìŠ¤)

        ì£¼ì˜/ê°€ì •:
            - OpenCVëŠ” BGR ì±„ë„ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë°˜ë“œì‹œ RGBë¡œ ë³€í™˜í•´ì•¼ ImageNet ì •ê·œí™” ë“±ê³¼ í˜¸í™˜ë©ë‹ˆë‹¤.
            - transformì´ numpy ì…ë ¥ì„ ë°›ì„ ê²½ìš°, ToPILImageê°€ ë§¨ ì•ì— ìˆì–´ì•¼ Resizeê°€ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.
            - ê¸¸ì´ ê³ ì •ì€ ë°°ì¹˜ í…ì„œ ìƒì„±(B, T, C, H, W)ì— í•„ìˆ˜ì…ë‹ˆë‹¤. ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ DataLoaderê°€ ì—ëŸ¬ë¥¼ ëƒ…ë‹ˆë‹¤.
            - self.fixed_len, ì…ë ¥ í•´ìƒë„(Resize í¬ê¸°)ëŠ” ëª¨ë¸/ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥.

        ì˜ˆì‹œ ì‚¬ìš©:
            x, y = dataset[i]
            # x.shape == (T, C, H, W), y == int
        """
        # (ë¹„ë””ì˜¤ ê²½ë¡œ, ë¼ë²¨ ì¸ë±ìŠ¤) - íŠœí”Œë¡œ ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¸ë±ìŠ¤ë¡œ í•˜ë‚˜ì˜ ì˜ìƒì— ì ‘ê·¼í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤.
        video, label = self.samples[idx]
        # ë¼ë²¨ëª…(ë””ë²„ê¹…ìš©)
        human_accident_class_name = self.class_names[label]

        # -------------------------------------------------------------
        # same_fpsëŠ” â€œì‹œê°„ ê°„ê²©â€ë§Œ ë§ì¶°ì¤ë‹ˆë‹¤.
        # ğŸŸ¢ ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ â€œë¹„ë””ì˜¤ì—ì„œ ì½ì€ í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì™¸ ì²˜ë¦¬ â†’ ê¸¸ì´ ê³ ì •(ìƒ˜í”Œë§/íŒ¨ë”©) â†’ í”„ë ˆì„ë³„ ì „ì²˜ë¦¬(BGRâ†’RGB, Resize/Normalize) â†’ (T, C, H, W) í…ì„œë¡œ ë³€í™˜â€í•˜ëŠ” ë‹¨ê³„
        # 1) ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  FPSë¥¼ 30ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
        frames = self.same_fps(video)  # ë°˜í™˜: numpy, shape=(T, H, W, C), ì±„ë„ ìˆœì„œ=BGR(OpenCV ê¸°ë³¸)

        # 2) ì˜ˆì™¸ ì²˜ë¦¬: ë¹„ë””ì˜¤ë¥¼ ì—´ì§€ ëª»í–ˆê±°ë‚˜ í”„ë ˆì„ì´ ë¹„ì–´ìˆë‹¤ë©´, í•™ìŠµì´ ëŠê¸°ì§€ ì•Šë„ë¡ ë”ë¯¸ í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        if frames is None or len(frames) == 0:
            # ë”ë¯¸ í”„ë ˆì„ì€ ê²€ì€ í™”ë©´(ëª¨ë‘ 0)ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. ê¸¸ì´ëŠ” self.fixed_lenìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.
            # í•´ìƒë„ëŠ” 224x224(ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë³´í†µ ë§ì¶¤), ì±„ë„ì€ 3(RGB ê°€ì •)ì´ ë©ë‹ˆë‹¤.
            frames = np.zeros((self.fixed_len, 224, 224, 3), dtype=np.uint8)

        # 3) ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ê³ ì •(self.fixed_len)í•˜ê¸° ìœ„í•œ ì¤€ë¹„: í˜„ì¬ ê¸¸ì´ Të¥¼ êµ¬í•©ë‹ˆë‹¤.
        T = len(frames)  # í˜„ì¬ ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ í”„ë ˆì„ ê°œìˆ˜

        # 4) ê¸¸ì´ ê³ ì • ë¡œì§
        if T >= self.fixed_len:
            # 4-1) í”„ë ˆì„ì´ ì¶©ë¶„íˆ ë§ê±°ë‚˜ ê°™ìœ¼ë©´, ê· ë“± ê°„ê²©ìœ¼ë¡œ self.fixed_lenê°œë¥¼ ê³¨ë¼
            #      ì „ì²´ êµ¬ê°„ì˜ ì •ë³´ë¥¼ ê³ ë¥´ê²Œ ìœ ì§€í•˜ë©´ì„œ ê¸¸ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤.
            #      ì˜ˆ: T=100, fixed_len=16 -> 0~99 êµ¬ê°„ì—ì„œ 16ê°œë¥¼ ê³¨ë¼ ë‹¤ìš´ìƒ˜í”Œë§
            indices = np.linspace(0, T - 1, self.fixed_len).astype(int)
            frames = frames[indices]
        else:
            # 4-2) í”„ë ˆì„ì´ ë¶€ì¡±í•˜ë©´, ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë°˜ë³µí•´ì„œ ë¶™ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ê¸¸ì´ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.
            #      ì´ë ‡ê²Œ í•˜ë©´ ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ ìˆœê°„ì´ ì •ì§€ëœ í˜•íƒœë¡œ ìœ ì§€ë˜ì–´ ëª¨ë¸ ì…ë ¥ ì°¨ì›ì„ ë§ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            pad_count = self.fixed_len - T  # ë¶€ì¡±í•œ ê°œìˆ˜ë§Œí¼
            pad = np.repeat(frames[-1:], pad_count, axis=0)  # ë§ˆì§€ë§‰ í”„ë ˆì„ì„ pad_countë§Œí¼ ë°˜ë³µ
            frames = np.concatenate([frames, pad], axis=0)  # ì›ë˜ í”„ë ˆì„ ë’¤ì— ë¶™ì—¬ ìµœì¢… ê¸¸ì´ ê³ ì •

        # 5) ì „ì²˜ë¦¬ëœ í”„ë ˆì„ í…ì„œë¥¼ ìŒ“ì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
        processed = []  # ì´ ë¦¬ìŠ¤íŠ¸ì— (C,H,W) í…ì„œë“¤ì„ ìˆœì„œëŒ€ë¡œ appendí•©ë‹ˆë‹¤.

        # 6) í”„ë ˆì„ì„ í•œ ì¥ì”© êº¼ë‚´ì–´ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        for f in frames:
            # 6-1) OpenCVëŠ” BGR ì±„ë„ ìˆœì„œë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì¼ë°˜ì ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸(RGB)ì— ë§ì¶”ê¸° ìœ„í•´ ë³€í™˜í•©ë‹ˆë‹¤.
            rgb = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)  # BGR -> RGB, shape ìœ ì§€: (H,W,C)

            if self.transform is not None:
                # 6-2) transform íŒŒì´í”„ë¼ì¸ ì ìš©(ê¶Œì¥ êµ¬ì„±):
                #   ToPILImage() -> Resize(224,224) -> ToTensor() -> Normalize(...)
                # ì£¼ì˜: ì…ë ¥ì´ numpyì´ë©´ ToPILImageê°€ ë¨¼ì € ìˆì–´ì•¼ Resizeê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
                img = self.transform(rgb)  # ê¸°ëŒ€ ê²°ê³¼: torch.Tensor, shape=(C,H,W), dtype=float
            else:
                # 6-3) transformì´ ì—†ë‹¤ë©´ ìµœì†Œí•œì˜ ë³€í™˜ì„ ì§ì ‘ ìˆ˜í–‰í•©ë‹ˆë‹¤.
                #      numpy(H,W,C)[0..255] -> tensor(C,H,W)[0..1]
                img = torch.from_numpy(rgb).permute(2, 0, 1).float() / 255.0

            # 6-4) ì²˜ë¦¬ëœ í”„ë ˆì„ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            processed.append(img)

        # 7) ë¦¬ìŠ¤íŠ¸ì— ìŒ“ì¸ í”„ë ˆì„ í…ì„œë“¤ì„ ì‹œê°„ì¶•(T) ê¸°ì¤€ìœ¼ë¡œ ìŠ¤íƒí•˜ì—¬ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ í…ì„œë¥¼ ë§Œë“­ë‹ˆë‹¤.
        #    ìµœì¢… shape: (T, C, H, W)
        #    ì´í›„ DataLoaderê°€ ë°°ì¹˜ë¥¼ ë§Œë“¤ë©´ ëª¨ë¸ ì…ë ¥ì€ (B, T, C, H, W)ì´ ë©ë‹ˆë‹¤.
        result = torch.stack(processed, dim=0)
        # =================================================================================

        # í˜„ì¬ ì˜ìƒì— ëŒ€í•œ classë¥¼ index(ë²ˆí˜¸)ë¡œ ê°€ì ¸ê°€ labelë¡œ ë¶™ì—¬ì¤ë‹ˆë‹¤.
        return result, label