import torch  # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch.nn as nn  # ì‹ ê²½ë§ ëª¨ë“ˆ(ë ˆì´ì–´, ì†ì‹¤ í•¨ìˆ˜ ë“±)ì„ í¬í•¨í•˜ëŠ” PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch.optim as optim  # ìµœì í™” ì•Œê³ ë¦¬ì¦˜(Adam, SGD ë“±)ì„ í¬í•¨í•˜ëŠ” PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬
import tensorboardX  # TensorBoard ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (íŒŒì¼ ê²½ë¡œ, ë””ë ‰í† ë¦¬ ìƒì„± ë“±)
import random  # ë‚œìˆ˜ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

from torch.utils.data import DataLoader  # ë°ì´í„°ì…‹ì„ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë¡œë“œí•˜ëŠ” PyTorch ìœ í‹¸ë¦¬í‹°
from torch.optim import lr_scheduler  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìœ„í•œ PyTorch ìœ í‹¸ë¦¬í‹°

# -------------------------------------------------------------------

from opts import parse_opts  # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±ì„ ìœ„í•œ opts.pyì—ì„œ parse_opts í•¨ìˆ˜ ì„í¬íŠ¸

from train import train_epoch  # í•™ìŠµ ë¡œì§ì´ êµ¬í˜„ëœ train.pyì—ì„œ train_epoch í•¨ìˆ˜ ì„í¬íŠ¸

from validation import val_epoch  # ê²€ì¦ ë¡œì§ì´ êµ¬í˜„ëœ validation.pyì—ì„œ val_epoch í•¨ìˆ˜ ì„í¬íŠ¸

from model import generate_model  # ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìƒì„±í•˜ëŠ” model.pyì—ì„œ generate_model í•¨ìˆ˜ ì„í¬íŠ¸

from dataset import get_training_set, get_validation_set  # ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¤ëŠ” dataset.pyì˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸

from mean import get_mean, get_std  # ë°ì´í„° ì •ê·œí™”ë¥¼ ìœ„í•œ í‰ê· , í‘œì¤€í¸ì°¨ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” mean.pyì˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸


from spatial_transforms import (    # ì´ë¯¸ì§€ í”„ë ˆì„ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜(augmentation) í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
    Compose,                        # ì—¬ëŸ¬ ë³€í™˜ì„ ë¬¶ì–´ì£¼ëŠ” í´ë˜ìŠ¤
    Normalize,                      # í…ì„œë¥¼ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”í•˜ëŠ” í´ë˜ìŠ¤
    Scale,                          # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ëŠ” í´ë˜ìŠ¤
    CenterCrop,                     # ì´ë¯¸ì§€ ì¤‘ì•™ì„ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    CornerCrop,                     # ì´ë¯¸ì§€ ëª¨ì„œë¦¬ë¥¼ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    MultiScaleCornerCrop,           # ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ëª¨ì„œë¦¬ë¥¼ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    MultiScaleRandomCrop,           # ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ëŠ” í´ë˜ìŠ¤
    RandomHorizontalFlip,           # ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì¢Œìš° ë°˜ì „í•˜ëŠ” í´ë˜ìŠ¤
    ToTensor,                       # PIL ì´ë¯¸ì§€ë‚˜ 'numpy ë°°ì—´'ì„ 'í…ì„œ'ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤
)

from temporal_transforms import LoopPadding, TemporalRandomCrop  # ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ì— ì ìš©í•  ì‹œê°„ì  ë³€í™˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸

from target_transforms import ClassLabel, VideoID  # íƒ€ê²Ÿ(ë¼ë²¨) ë°ì´í„°ì— ì ìš©í•  ë³€í™˜ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸

from target_transforms import Compose as TargetCompose  # íƒ€ê²Ÿ ë³€í™˜ì„ ë¬¶ì–´ì£¼ê¸° ìœ„í•œ Compose í´ë˜ìŠ¤ ì„í¬íŠ¸


def resume_model(opt, model, optimizer):
    """
    Resume model

    ì²´í¬í¬ì¸íŠ¸(checkpoint)ë¡œë¶€í„° ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ë¶ˆëŸ¬ì™€ í•™ìŠµì„ ì´ì–´ê°ˆ ì¤€ë¹„ë¥¼ í•˜ëŠ” í•¨ìˆ˜.
    ì…ë ¥:
        opt       : argparseë¡œ íŒŒì‹±ëœ ì˜µì…˜ ê°ì²´ (opt.resume_path ê°€ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œì—¬ì•¼ í•¨)
        model     : ë¯¸ë¦¬ ìƒì„±ëœ PyTorch ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        optimizer : ë¯¸ë¦¬ ìƒì„±ëœ PyTorch ì˜µí‹°ë§ˆì´ì € ì¸ìŠ¤í„´ìŠ¤
    ë°˜í™˜:
        start_epoch : ë‹¤ìŒì— í•™ìŠµì„ ì‹œì‘í•  epoch ë²ˆí˜¸ (ë³´í†µ ì €ì¥ëœ epoch + 1)
    ì£¼ì˜:
        - ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì˜ ë‚´ë¶€ êµ¬ì¡°ëŠ” { "epoch": int, "state_dict": model_state_dict,
                                    "optimizer_state_dict": optimizer_state_dict } 
                                í˜•íƒœë¥¼ ê¸°ëŒ€í•¨.
    """
    # 1) ë””ìŠ¤í¬ì—ì„œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¡œë“œ
    # torch.loadëŠ” íŒŒì¼ì— ì €ì¥ëœ íŒŒì´ì¬ ê°ì²´(ì—¬ê¸°ì„œëŠ” dict)ë¥¼ ë³µì›í•¨.
    # ì£¼ì˜: GPUì—ì„œ ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ CPU í™˜ê²½ì—ì„œ ë¶ˆëŸ¬ì˜¤ë©´ ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    #       ì‹¤ì œ ì½”ë“œì—ì„œëŠ” map_location=device ì‚¬ìš©ì„ ê¶Œì¥.
    checkpoint = torch.load(opt.resume_path)

    # 2) ì²´í¬í¬ì¸íŠ¸ ì•ˆì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°(state_dict)ë¥¼ í˜„ì¬ ëª¨ë¸ ê°ì²´ì— ì ìš©
    # checkpoint["state_dict"]ëŠ” íŒŒë¼ë¯¸í„° ì´ë¦„->í…ì„œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•¨.
    # ë§Œì•½ ì €ì¥í•  ë•Œ DataParallel(model)ì„ ì‚¬ìš©í•´ ì €ì¥í–ˆë‹¤ë©´ í‚¤ ì•ì— 'module.'ì´ ë¶™ì–´ìˆì„ ìˆ˜ ìˆë‹¤.
    # ëª¨ë¸ êµ¬ì¡°ê°€ í˜„ì¬ ëª¨ë¸ê³¼ ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ load_state_dictì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ.
    model.load_state_dict(checkpoint["state_dict"])

    # 3) ì²´í¬í¬ì¸íŠ¸ ì•ˆì˜ ì˜µí‹°ë§ˆì´ì € ìƒíƒœ(state_dict)ë¥¼ í˜„ì¬ ì˜µí‹°ë§ˆì´ì €ì— ì ìš©
    # ì˜µí‹°ë§ˆì´ì € ìƒíƒœì—ëŠ” learning rate, ëª¨ë©˜í…€ ë²„í¼, param_groups, ê·¸ë¦¬ê³  ë‚´ë¶€ ëª¨ë©˜í…€ ì¶”ì •ê°’ ë“±ì´ í¬í•¨ë¨.
    # ì˜µí‹°ë§ˆì´ì € êµ¬ì¡°(param_groups ë“±)ê°€ ë‹¤ë¥´ë©´ load_state_dictì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ.
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])

    # 4) ë³µì›ëœ ì²´í¬í¬ì¸íŠ¸ê°€ ì–¸ì œ ì €ì¥ëœ ê²ƒì¸ì§€ ì‚¬ìš©ìì—ê²Œ ì¶œë ¥
    # checkpoint["epoch"]ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•œ ì—í­ ë²ˆí˜¸(ì •ìˆ˜)ë¥¼ ê°€ì§.
    print("Model Restored from Epoch {}".format(checkpoint["epoch"]))

    # 5) í•¨ìˆ˜ í˜¸ì¶œìì—ê²Œ ë°˜í™˜í•  'ë‹¤ìŒ ì‹œì‘ ì—í­' ê²°ì •
    # ë³´í†µ ì €ì¥ëœ epochê°€ 5ë¼ë©´, ìš°ë¦¬ëŠ” 6ë²ˆì§¸ ì—í­(epoch=6)ë¶€í„° í•™ìŠµì„ ì´ì–´ê°€ë¯€ë¡œ +1 í•´ì¤€ë‹¤.
    start_epoch = checkpoint["epoch"] + 1

    # 6) ê³„ì‚°ëœ ì‹œì‘ ì—í­ ë°˜í™˜
    return start_epoch



def get_loaders(opt):
    """Make dataloaders for train and validation sets"""
    # ----------------------------------
    # âœ… train loader
    opt.mean = get_mean(opt.norm_value, dataset=opt.mean_dataset)  # ì •ê·œí™”ì— ì‚¬ìš©í•  í‰ê· ê°’ ê³„ì‚°
    if opt.no_mean_norm and not opt.std_norm:  # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ê·œí™”ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        norm_method = Normalize([0, 0, 0], [1, 1, 1])  # ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ” ê²ƒê³¼ ê°™ì€ íš¨ê³¼ (0ì„ ë¹¼ê³  1ë¡œ ë‚˜ëˆ”)
    elif not opt.std_norm:  # í‰ê·  ì •ê·œí™”ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        norm_method = Normalize(opt.mean, [1, 1, 1])  # í‰ê· ê°’ë§Œ ë¹¼ê³ , 1ë¡œ ë‚˜ëˆ„ì–´ í‘œì¤€í¸ì°¨ ì •ê·œí™”ëŠ” ìƒëµ
    else:  # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ê·œí™”ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        norm_method = Normalize(opt.mean, opt.std)  # í‰ê· ì„ ë¹¼ê³  í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ”
    
    spatial_transform = Compose(  # í•™ìŠµ ë°ì´í„°ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜ë“¤ì„ ì •ì˜
        [
            # crop_method,
            Scale((opt.sample_size, opt.sample_size)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ (sample_size, sample_size)ë¡œ ì¡°ì ˆ
            # RandomHorizontalFlip(),
            ToTensor(opt.norm_value),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  norm_valueë¡œ ë‚˜ëˆ”
            norm_method,  # ìœ„ì—ì„œ ì •ì˜í•œ ì •ê·œí™” ë°©ë²• ì ìš©
        ]
    )
    
    temporal_transform = TemporalRandomCrop(16)  # ë¹„ë””ì˜¤ í”„ë ˆì„ ì‹œí€€ìŠ¤ì—ì„œ 16 í”„ë ˆì„ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ëƒ„
    
    target_transform = ClassLabel()  # íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ ë¼ë²¨ë§Œ ì¶”ì¶œ
    
    training_data = get_training_set(  # í•™ìŠµ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
        opt, spatial_transform, temporal_transform, target_transform  # ì˜µì…˜ê³¼ ë³€í™˜ë“¤ì„ ì „ë‹¬
    )
    
    train_loader = torch.utils.data.DataLoader(  # í•™ìŠµ ë°ì´í„° ë¡œë” ìƒì„±
        training_data,  # ìœ„ì—ì„œ ìƒì„±í•œ ë°ì´í„°ì…‹ ê°ì²´
        batch_size=opt.batch_size,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        shuffle=True,  # ì—í­ë§ˆë‹¤ ë°ì´í„°ë¥¼ ì„ì„ì§€ ì—¬ë¶€ (í•™ìŠµ ì‹œì—ëŠ” Trueê°€ ì¼ë°˜ì )
        num_workers=opt.num_workers,  # ë°ì´í„° ë¡œë”©ì— ì‚¬ìš©í•  ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ìˆ˜
        pin_memory=True,  # GPUë¡œ ë°ì´í„°ë¥¼ ë” ë¹¨ë¦¬ ì „ì†¡í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ì— ê³ ì •
    )

    # ----------------------------------
    # âœ… validation loader
    spatial_transform = Compose(  # ê²€ì¦ ë°ì´í„°ì— ì ìš©í•  ê³µê°„ì  ë³€í™˜ë“¤ì„ ì •ì˜ (ë³´í†µ augmentation ì œì™¸)
        [
            Scale((opt.sample_size, opt.sample_size)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ (sample_size, sample_size)ë¡œ ì¡°ì ˆ
            # CenterCrop(opt.sample_size),
            ToTensor(opt.norm_value),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  norm_valueë¡œ ë‚˜ëˆ”
            norm_method,  # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì •ê·œí™” ë°©ë²• ì ìš©
        ]
    )
    target_transform = ClassLabel()  # íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ ë¼ë²¨ë§Œ ì¶”ì¶œ
    temporal_transform = LoopPadding(16)  # ë¹„ë””ì˜¤ í”„ë ˆì„ ì‹œí€€ìŠ¤ê°€ 16ë³´ë‹¤ ì§§ì„ ê²½ìš°, ì•ë¶€ë¶„ì„ ë°˜ë³µí•´ì„œ 16 í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¦
    validation_data = get_validation_set(  # ê²€ì¦ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
        opt, spatial_transform, temporal_transform, target_transform  # ì˜µì…˜ê³¼ ë³€í™˜ë“¤ì„ ì „ë‹¬
    )
    val_loader = torch.utils.data.DataLoader(  # ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±
        validation_data,  # ìœ„ì—ì„œ ìƒì„±í•œ ë°ì´í„°ì…‹ ê°ì²´
        batch_size=opt.batch_size,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        shuffle=False,  # ê²€ì¦ ì‹œì—ëŠ” ë°ì´í„°ë¥¼ ì„ì§€ ì•ŠìŒ (ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´)
        num_workers=opt.num_workers,  # ë°ì´í„° ë¡œë”©ì— ì‚¬ìš©í•  ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ìˆ˜
        pin_memory=True,  # GPUë¡œ ë°ì´í„°ë¥¼ ë” ë¹¨ë¦¬ ì „ì†¡í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ì— ê³ ì •
    )
    return train_loader, val_loader  # ìƒì„±ëœ í•™ìŠµ ë° ê²€ì¦ ë°ì´í„° ë¡œë” ë°˜í™˜

# --------------------------------------------------------------------
# 2. main_worker() í•¨ìˆ˜ë¥¼ ë“¤ì—¬ë‹¤ë³´ì~
def main_worker():
    # 3. parsing
    opt = parse_opts()  # ì»¤ë§¨ë“œë¼ì¸ ì¸ìë“¤ì„ íŒŒì‹±í•˜ì—¬ opt ê°ì²´ì— ì €ì¥
    # parser : compilerì˜ ì¼ë¶€ë¡œ ì»´íŒŒì¼ëŸ¬ë‚˜ ì¸í„°í”„ë¦¬í„°ì—ì„œ ì›ì‹œ í”„ë¡œê·¸ë¨ì„ ì½ì–´ ë“¤ì—¬ ê·¸ ë¬¸ì¥ì˜ êµ¬ì¡°ë¥¼ ì•Œì•„ë‚´ëŠ” parsing(êµ¬ë¬¸ ë¶„ì„)ì„ í–‰í•˜ëŠ” í”„ë¡œê·¸ë¨
    # opt = options(ì˜µì…˜ë“¤) ì˜ ì¤„ì„ë§ / ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ë°›ì€ ì„¤ì •ê°’ë“¤ì„ ëª¨ì•„ë‘” ê°ì²´
    print(opt)  # íŒŒì‹±ëœ ì˜µì…˜ë“¤ì„ ì¶œë ¥í•˜ì—¬ í™•ì¸

    # ğŸš¨ 4. ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ(seed) ê³ ì •
    seed = 1  # ì‹œë“œ ê°’ ì„¤ì •
    random.seed(seed)  # íŒŒì´ì¬ ë‚´ì¥ random ëª¨ë“ˆì˜ ì‹œë“œ ê³ ì •
    np.random.seed(seed)  # numpyì˜ ì‹œë“œ ê³ ì •
    torch.manual_seed(seed)  # PyTorchì˜ CPU ì—°ì‚°ì— ëŒ€í•œ ì‹œë“œ ê³ ì •
    # ì´ë ‡ê²Œ ê³ ì •í•˜ëŠ” ì´ìœ  : ë‚´ê°€ ë§Œë“  ëª¨ë¸ì„ ë‹¤ì‹œ ëŒë ¸ì„ ë•Œ, í˜¹ì€ ë‹¤ë¥¸ ì‚¬ëŒì´ ë‚´ ì½”ë“œë¥¼ ëŒë ¸ì„ ë•Œ ê²°ê³¼ê°€ ë˜‘ê°™ì´ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ.

    # 5. CUDA for PyTorch
    device = torch.device(f"cuda:{opt.gpu}" if opt.use_cuda else "cpu")  # --use_cuda ì˜µì…˜ì´ ìˆìœ¼ë©´ ì§€ì •ëœ GPUë¥¼, ì—†ìœ¼ë©´ CPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •

    # 6. tensorboard
    summary_writer = tensorboardX.SummaryWriter(log_dir="tf_logs")  # TensorBoard ë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì • ë° writer ê°ì²´ ìƒì„±
    """ 
    ğŸŸ¡ SummaryWriter   
        ã„´ ë¡œê·¸(ìŠ¤ì¹¼ë¼, ì´ë¯¸ì§€, íˆìŠ¤í† ê·¸ë¨, ê·¸ë˜í”„ ë“±)ë¥¼ ë””ìŠ¤í¬ì— ê¸°ë¡í•˜ëŠ” "ì“°ê¸° ë„êµ¬(writer)" í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
        ã„´ ì´ ê°ì²´ì˜ add_s calar, add_image, add_histogram, add_graph ë“± ë©”ì„œë“œë¥¼ í†µí•´ ì´ë²¤íŠ¸ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤. 
    ğŸŸ¡ log_dir="tf_logs"  ->   ì´ë²¤íŠ¸ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    
    # 7. defining model
    model = generate_model(opt, device)  # ì„¤ì •(opt)ì— ë§ëŠ” model(model.py íŒŒì¼ ì°¸ì¡°)ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ ì¥ì¹˜(device)ë¡œ ì´ë™

    # 8. get data loaders
    train_loader, val_loader = get_loaders(opt)  # í•™ìŠµ ë° ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±

    # 9. optimizer - ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ë¥¼ í•™ìŠµ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•´ì£¼ëŠ” ì•Œê³ ë¦¬ì¦˜
    crnn_params = list(model.parameters())  # ìµœì í™”í•  ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´
    optimizer = torch.optim.Adam(  # Adam ì˜µí‹°ë§ˆì´ì € ìƒì„±
        crnn_params, lr=opt.lr_rate, weight_decay=opt.weight_decay  # ëª¨ë¸ íŒŒë¼ë¯¸í„°, í•™ìŠµë¥ , ê°€ì¤‘ì¹˜ ê°ì‡ (L2 ì •ê·œí™”) ì„¤ì •
    )
    # ğŸ” optimizer ì„¤ëª…
        # 1. ì‹ ê²½ë§ì€ ì²˜ìŒì— ëœë¤í•œ ê°€ì¤‘ì¹˜(weight) ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
        # 2. ì…ë ¥ ë°ì´í„°ë¥¼ í†µê³¼ì‹œì¼œ ì¶œë ¥(prediction) ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        # 3. ì¶œë ¥ê³¼ ì •ë‹µ(label)ì„ ë¹„êµí•´ ì†ì‹¤(loss) ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        # 4. ì—­ì „íŒŒ(backpropagation) ë¡œ ê° ê°€ì¤‘ì¹˜ê°€ ì†ì‹¤ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ê¸°ìš¸ê¸°(gradient) ë¥¼ êµ¬í•©ë‹ˆë‹¤.
        # 5. ë§ˆì§€ë§‰ìœ¼ë¡œ optimizer ê°€ ê·¸ ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ê¸ˆì”© ì¡°ì •í•©ë‹ˆë‹¤.
        # ì´ ê³¼ì •ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ë©´ì„œ ëª¨ë¸ì´ ì ì  "ë°ì´í„°ì— ì˜ ë§ê²Œ" í•™ìŠµë©ë‹ˆë‹¤.

    
    # 10. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬(Learning Rate Scheduler) ì„¤ì • ì½”ë“œ
    # scheduler = lr_scheduler.ReduceLROnPlateau(
    # 	optimizer, 'min', patience=opt.lr_patience 
    # )

    # 11. ì†ì‹¤í•¨ìˆ˜
    criterion = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ CrossEntropy ì†ì‹¤ í•¨ìˆ˜ ì •ì˜

    # 12. resume model - ì–´ë””ì„œ í•™ìŠµì„ ì‹œì‘í•  ê²ƒì¸ê°€?
    if opt.resume_path:  # â€œtruthyâ€(ë¹ˆ ë¬¸ìì—´/None/Falseê°€ ì•„ë‹Œ ê°’)ì¸ì§€ ê²€ì‚¬ / --resume_path ì˜µì…˜ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì£¼ì–´ì§„ ê²½ìš°
        start_epoch = resume_model(opt, model, optimizer)  # ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ë³µì›í•˜ê³  ì‹œì‘ ì—í­ì„ ë°›ì•„ì˜´
    else:  # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì£¼ì–´ì§€ì§€ ì•Šì€ ê²½ìš° (ì²˜ìŒë¶€í„° í•™ìŠµ)
        start_epoch = 1  # 1 ì—í­ë¶€í„° í•™ìŠµ ì‹œì‘

    # 13. start training - í•™ìŠµ ì‹œì‘
    for epoch in range(start_epoch, opt.n_epochs + 1):  # ì‹œì‘ ì—í­ë¶€í„° ë§ˆì§€ë§‰ ì—í­ê¹Œì§€ ë°˜ë³µ
        train_loss, train_acc = train_epoch(  # 1 ì—í­ ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµ
            model, train_loader, criterion, optimizer, epoch, opt.log_interval, device  # í•„ìš”í•œ ëª¨ë“  ê°ì²´ì™€ ì„¤ì •ì„ ì „ë‹¬
        )
        val_loss, val_acc = val_epoch(model, val_loader, criterion, device)  # 1 ì—í­ í•™ìŠµ í›„ ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

        # saving weights to checkpoint
        if (epoch) % opt.save_interval == 0:  # í˜„ì¬ ì—í­ì´ 'save_interval'ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§ˆ ë•Œë§ˆë‹¤
            # scheduler.step(val_loss)
            # write summary
            summary_writer.add_scalar(  # TensorBoardì— í•™ìŠµ ì†ì‹¤ ê¸°ë¡
                "losses/train_loss", train_loss, global_step=epoch  # 'losses/train_loss' íƒœê·¸ë¡œ, í˜„ì¬ ì—í­ì„ xì¶•ìœ¼ë¡œ í•˜ì—¬ ê¸°ë¡
            )
            summary_writer.add_scalar("losses/val_loss", val_loss, global_step=epoch)  # TensorBoardì— ê²€ì¦ ì†ì‹¤ ê¸°ë¡
            summary_writer.add_scalar(  # TensorBoardì— í•™ìŠµ ì •í™•ë„ ê¸°ë¡
                "acc/train_acc", train_acc * 100, global_step=epoch  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ë¡
            )
            summary_writer.add_scalar("acc/val_acc", val_acc * 100, global_step=epoch)  # TensorBoardì— ê²€ì¦ ì •í™•ë„ ê¸°ë¡

            state = {  # ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥í•  ì •ë³´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì„±
                "epoch": epoch,  # í˜„ì¬ ì—í­ ë²ˆí˜¸
                "state_dict": model.state_dict(),  # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
                "optimizer_state_dict": optimizer.state_dict(),  # ì˜µí‹°ë§ˆì´ì €ì˜ ìƒíƒœ
            }
            torch.save(  # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì €ì¥
                state,  # ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
                os.path.join(  # ì €ì¥ ê²½ë¡œì™€ íŒŒì¼ ì´ë¦„ ìƒì„±
                    "snapshots", f"{opt.model}-Epoch-{epoch}-Loss-{val_loss:.4f}.pth"  # snapshots í´ë”ì— ëª¨ë¸, ì—í­, ì†ì‹¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì´ë¦„ìœ¼ë¡œ ì €ì¥
                ),
            )
            print("Epoch {} model saved!\n".format(epoch))  # ëª¨ë¸ ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥


if __name__ == "__main__":
    # 1. main_worker í•¨ìˆ˜ê°€ ìµœì´ˆ ì‹œì‘ì§€ì ì…ë‹ˆë‹¤.
    main_worker()  # ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main_worker í•¨ìˆ˜ í˜¸ì¶œ
