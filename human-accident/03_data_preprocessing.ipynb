{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4e0c29",
   "metadata": {},
   "source": [
    "# 🟩 데이터 전처리  \n",
    "\n",
    "- 모델 선택 (나는 이 모델을 사용하여 학습 및 구현을 할 것이다.)  \n",
    "    - cnn-lstm  \n",
    "        - https://github.com/pranoyr/cnn-lstm  \n",
    "        - Action (Video) Classification  \n",
    "\n",
    "- 해당 모델의 데이터셋이 도대체 어떻게 생긴 것인지 먼저 파악해야함.  \n",
    "    - https://github.com/pranoyr/cnn-lstm/blob/master/dataset.py  \n",
    "        - **`UCF101`**  \n",
    "            ```python\n",
    "            def get_training_set(opt, spatial_transform, temporal_transform,  \n",
    "                    target_transform):  \n",
    "                if opt.dataset == 'ucf101':  \n",
    "                    training_data = UCF101(  \n",
    "                        opt.video_path,  \n",
    "                        opt.annotation_path,  \n",
    "                        'training',  \n",
    "                        spatial_transform=spatial_transform,  \n",
    "                        temporal_transform=temporal_transform,  \n",
    "                        target_transform=target_transform)  \n",
    "\n",
    "                return training_data  \n",
    "            ```\n",
    "\n",
    "- UCF101을 사용함.  \n",
    "    - https://www.kaggle.com/datasets/matthewjansen/ucf101-action-recognition  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f407b8",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## 🟢 1. 파악하기  \n",
    "\n",
    "### 🟡 UCF101이라는게 무엇인가?  \n",
    "https://wikidocs.net/164441  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 🟡 UCF101기준으로 전처리해야한다.  \n",
    "- 조건  \n",
    "    - 먼저 video를 기준으로 하며 그에 따르는 lable (annotation???)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15d387",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## 🟢 2. 먼저 동영상과 라벨을 가져와서 가공하여 저장 (전처리)  \n",
    "(일단 먼저 하나의 동영상만 가져와서 해보겠습니다.)  \n",
    "\n",
    "https://bkshin.tistory.com/entry/OpenCV-3-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%9E%85%EC%B6%9C%EB%A0%A5  \n",
    "https://blog.naver.com/life4happy/222499735708  \n",
    "https://scribblinganything.tistory.com/492  \n",
    "https://yonghyn.tistory.com/87  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0641b40",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 🟡 2-1. 비디오 파일을 녹화, 저장하는 절차에 대해서 알아보겠습니다.  \n",
    "\n",
    "- 동영상 파일 읽기  \n",
    "\n",
    "- 주요 함수  \n",
    "    | 함수/변수 | 설명 |  \n",
    "    | :--- | :--- |\n",
    "    | `cv2.VideoCapture()` | 현재 입력된 동영상 파일의 정보를 불러옵니다. 동영상 파일을 읽기 위해 필요한 프레임 설정, 코덱 등의 정보를 가져옵니다. |  \n",
    "    | `capture.read()` | 동영상 파일에서 프레임을 가져와 압축을 해제한 후, `ret`(bool)과 `frame`(ndarray)을 반환합니다. `ret`는 프레임을 정상적으로 읽어왔는지 알려주고, `frame`에는 현재 프레임 정보가 담깁니다. |  \n",
    "    | `cv2.CAP_PROP_POS_FRAMES` | 현재 프레임의 수 |  \n",
    "    | `cv2.CAP_PROP_FRAME_COUNT` | 총 프레임의 수 |  \n",
    "    | `cv2.imshow(videoName, frame)` | `videoName`은 윈도우에 표시할 이름이고, `frame`은 윈도우에 출력할 동영상 프레임 변수입니다. |  \n",
    "    | `cv2.waitKey(33) == ord('q')` | `waitKey`는 입력된 ms만큼 대기한 후 다음 프레임으로 넘어가는 대기 변수입니다. `ord`는 문자를 유니코드 값으로 변환하는 데 사용됩니다. 이 코드는 다음 프레임으로 넘어가기 위해 대기하는 동안 'q'가 입력되었는지 확인합니다. |  \n",
    "    | `capture.release()` | 동영상 파일을 닫고 메모리를 해제합니다. |  \n",
    "    | `cv2.destroyAllWindows()` | 동영상 재생이 끝난 후 모든 윈도우를 닫습니다. |  \n",
    "\n",
    "<br>\n",
    "\n",
    "- VideoWriter객체를 생성, 인코딩 코덱,초당 프레임, 프레임 크기 등의 환경을 기반으로, 이미지 프레임을 write()함수를 이용하여, 비디오파일에 저장/녹화하게 됩니다.  \n",
    "\n",
    "- 주요 함수  \n",
    "    | 함수 | 설명 | 반환값 |  \n",
    "    | :--- | :--- | :--- |\n",
    "    | `cv2.VideoWriter([filename, fourcc, fps, frameSize[, isColor]])` | 비디오 출력 객체를 생성합니다.<br>• **fourcc**: 비디오 저장 방식/파일명을 나타내는 코덱 문자입니다.<br>• **fps**: 초당 프레임<br>• **frameSize**: 동영상 화면 사이즈 | `VideoWriter object` |  \n",
    "    | `cv2.VideoWriter.write(image)` | 비디오 파일에 이미지 프레임을 출력, 저장합니다. | - |  \n",
    "    | `cv2.VideoWriter.release()` | 비디오 출력 객체를 해제합니다. | - |  \n",
    "    | `cv2.VideoWriter.get(id)` | 동영상 파일의 특성값(property)을 확인합니다. | - |  \n",
    "\n",
    "<br>\n",
    "\n",
    "- VideoWirter에 사용되는 인코딩 방법은 정의를 해줘야 합니다. `fourcc`에 지정할 수 있는 인코딩 방법입니다.  \n",
    "\n",
    "- `avi`, `mp4`는 `XVID`로 지정하면 됩니다.  \n",
    "\n",
    "- 다음은 `fourcc`로 지정할 수 있는 **`코덱의 종류`** 입니다.  \n",
    "    | fourcc | 코덱명 |  \n",
    "    | :--- | :--- |\n",
    "    | `cv2.VideoWriter_fourcc(*'PIM1')` | MPEG-1 |  \n",
    "    | `cv2.VideoWriter_fourcc(*'MJPG')` | Motion-JPEG |  \n",
    "    | `cv2.VideoWriter_fourcc(*'DIVX')` | DIVX 4.0 이후 버젼 |  \n",
    "    | `cv2.VideoWriter_fourcc(*'XVID')` | XVID, MPEG-4 |  \n",
    "    | `cv2.VideoWriter_fourcc(*'MPEG')` | MPEG |  \n",
    "    | `cv2.VideoWriter_fourcc(*'X264')` | H.264/AVC |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc0bb8",
   "metadata": {},
   "source": [
    "#### ⚫ 동영상 경로 확인 및 지정  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba1fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load .env\n",
    "load_dotenv()\n",
    "\n",
    "# [MacOS] 현재 데이터셋이 있는 경로\n",
    "mac_path = os.environ.get(\"macbook_path\")\n",
    "\n",
    "# [Windows] 현재 데이터셋이 있는 경로\n",
    "windows_source_path = \"D:\\\\078.스마트 제조 시설 안전 감시를 위한 데이터\\\\3.개방데이터\\\\1.데이터\\\\Validation\\\\01.원천데이터\\\\VS\\\\human-accident\"\n",
    "# windows_lableing_path = \"D:\\\\078.스마트 제조 시설 안전 감시를 위한 데이터\\\\3.개방데이터\\\\1.데이터\\\\Validation\\\\02.라벨링데이터\\\\VL\\\\human-accident\"   # 라벨데이터는 필요없습니다.\n",
    "# 반드시 마지막 최종 경로는 폴더가 아닌 파일이 되어야 한다. 그렇지 않으면 PermissionError가 발생한다.\n",
    "\n",
    "# 내가 전처리할 경로\n",
    "data_source_path = \"./data/safety-data/Validation/01_source_data/human-accident/\"  # 영상 자체가 라벨이 되는 것이다.\n",
    "# data_labeling_path = \"./data/safety-data/Validation/02_labeling_data/human-accident/\"   # 라벨데이터는 필요없습니다.\n",
    "\n",
    "# human-accident의 class\n",
    "human_accident_class = [\"bump\", \"fall-down\", \"fall-off\", \"hit\", \"jam\", \"no-accident\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed692163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\\rgb\\human-accident_bump_rgb_0001_cctv1\\human-accident_bump_rgb_0001_cctv1.mp4\n"
     ]
    }
   ],
   "source": [
    "# 임시로 특정 경로를 고정시켜둠.\n",
    "# 하나의 동영상을 타겟으로 path를 고정시켰습니다.\n",
    "fix_path = (\n",
    "    \"\\\\\"\n",
    "    + \"rgb\"\n",
    "    + \"\\\\\"\n",
    "    + \"human-accident_bump_rgb_0001_cctv1\"\n",
    "    + \"\\\\\"\n",
    "    + \"human-accident_bump_rgb_0001_cctv1.mp4\"\n",
    ")\n",
    "\n",
    "decided_path = windows_source_path + \"\\\\\" + human_accident_class[0] + fix_path\n",
    "print(decided_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e939ee",
   "metadata": {},
   "source": [
    "#### ⚫ 동영상 객체 생성  \n",
    "cv2.VideoCapture() : 동영상 입력하는 OpenCV의 함수이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1185cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 동영상 객체 생성\n",
    "cap = cv2.VideoCapture(decided_path)  # 동영상 캡쳐 객체 생성  ---①"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd4f1f",
   "metadata": {},
   "source": [
    "#### ⚫ 동영상 파일 단순 읽기  \n",
    "- FRAME  \n",
    "    - 동영상은 여러 프레임 이미지의 합이라고 생각하시면 위 코드를 이해하기가 쉽습니다. 단편적인 프레임 이미지를 빠른 시간에 보여주면 움직이는 동영상처럼 보이죠? 위 코드도 하나의 프레임 이미지를 빠른 시간에 보여주는 방식으로 동작합니다. cv2.waitKey(25) 코드가 없다면 프레임이 너무 빨리 넘어가 눈으로 볼 수 없습니다. 하지만 25ms의 지연을 주면서 각 프레임을 화면에 표시해주기 때문에 우리는 동영상을 볼 수 있습니다. cv2.waitKey() 안에 들어가는 숫자를 지연 시간이라고 합니다. 25보다 작은 숫자를 넣어주면 화면이 동영상이 빠르게 재생되는 것처럼 보이고, 25보다 큰 숫자를 넣어주면 동영상이 천천히 재생되는 것처럼 보일 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a94fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps : 30\n",
      "fps_total : 393\n",
      "width : 1920\n",
      "height : 1080\n",
      "size : (1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "# 동영상의 fps를 확인\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"fps : {fps}\")\n",
    "\n",
    "# 총 프레임의 수\n",
    "fps_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"fps_total : {fps_total}\")\n",
    "\n",
    "# 동영상의 넓이 확인\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(f\"width : {width}\")\n",
    "\n",
    "# 동영상의 높이 확인\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"height : {height}\")\n",
    "\n",
    "# width, height\n",
    "size = (width, height)\n",
    "print(f\"size : {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c68ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 동영상 파일 단순 읽어서 확인하는 코드입니다.\n",
    "\n",
    "# if cap.isOpened():                      # 캡쳐 객체 초기화 확인 (동영상 파일 열기 성공 여부 확인)\n",
    "#     while True:\n",
    "#         ret, img = cap.read()           # 동영상 파일에서 프레임 읽기\n",
    "#         if ret:  # 프레임 읽기 정상\n",
    "#             cv2.imshow(decided_path, img)  # (제목, 표시하고자하는 img)를 지정하여 화면에 표시\n",
    "#             cv2.waitKey(25)             # 25ms 지연(40fps로 가정)\n",
    "#             print(\n",
    "#                 f\"현재 프레임 확인 : {int(cap.get(cv2.CAP_PROP_POS_FRAMES))}\"\n",
    "#             )  # 현재 프레임 확인\n",
    "#         else:                           # 다음 프레임 읽을 수 없음..\n",
    "#             break                       # 재생 완료.. (while문 종료)\n",
    "# else:\n",
    "#     print(\"can't open video.\")          # 캡쳐 객체 초기화 실패\n",
    "# cap.release()                           # 캡쳐 자원 반납 (메모리 반납)\n",
    "# cv2.destroyAllWindows()                 # 재생이 끝난 후 imshow 창 모두 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c45a97",
   "metadata": {},
   "source": [
    "#### ⚫ 동영상 쓰기 (인코딩)  \n",
    "- 읽어들인 영상 프레임들을 저장하는 방식입니다.  \n",
    "- 기존 동영상 파일을 읽는 것뿐만 아니라,  \n",
    "- cv2.VideoWriter  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b7d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# four_cc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "\n",
    "# # DIVX 인코딩 방법 정의\n",
    "# out_path_and_setting = cv2.VideoWriter(\n",
    "#     # data_source_path + human_accident_class[0] + \"/test_out.avi\",  # 저장할 PATH\n",
    "#     \"./data/test_out.avi\",\n",
    "#     four_cc,  # four_cc : fourcc 코덱 선정\n",
    "#     fps,  # fps : 프레임 수\n",
    "#     size,  # size : (튜플) 화면의 가로x세로 값\n",
    "#     isColor=True, # False의 경우 흑백채널입니다.\n",
    "# )\n",
    "\n",
    "# if cap.isOpened():  # 캡쳐 객체 초기화 확인 (동영상 파일 열기 성공 여부 확인)\n",
    "#     while True:\n",
    "#         ret, img = cap.read()  # 동영상 파일에서 프레임 읽기\n",
    "\n",
    "#         # 프레임 읽기 정상\n",
    "#         if ret:\n",
    "#             # 🔥🔥🔥🔥🔥 새로 쓰기\n",
    "#             out_path_and_setting.write(img)\n",
    "\n",
    "#             # imshow(제목, 표시하고자하는 img) 를 지정하여 화면에 표시\n",
    "#             cv2.imshow(decided_path, img)\n",
    "#             cv2.waitKey(25)  # 25ms 지연(40fps로 가정)\n",
    "#             # waitKey를 1로 설정하였다면, 각 frame을 1밀리초 동안 표시 후 다음 프레임으로 이동하며, 모든 프레임을 처리한 후 키보드의 'q' 키를 누르면 영상이 꺼집니다.\n",
    "\n",
    "#             # print(f\"현재 프레임 확인 : {int(cap.get(cv2.CAP_PROP_POS_FRAMES))}\")\n",
    "\n",
    "#             # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#             #     break\n",
    "\n",
    "#         else:  # 다음 프레임 읽을 수 없음..\n",
    "#             print(f\"정상적으로 재생 후 종료되었습니다.\")\n",
    "#             break  # 재생 완료.. (while문 종료)\n",
    "\n",
    "# else:\n",
    "#     print(\"can't open video.\")  # 캡쳐 객체 초기화 실패\n",
    "\n",
    "# cap.release()  # 캡쳐 자원 반납 (메모리 반납)\n",
    "# out_path_and_setting.release()\n",
    "# cv2.destroyAllWindows()  # 재생이 끝난 후 imshow 창 모두 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adbf34",
   "metadata": {},
   "source": [
    "여기까지 OpenCV 라이브러리를 사용하여 단순히 하나의 영상을 읽고, 별도로 저장해보았습니다.  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2091f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 🟡 2-2. os 라이브러리 사용하여 데이터를 읽고, 위 cv2코드를 통해 변환 및 저장합니다.  \n",
    "\n",
    "\n",
    "#### ⚫ 탐색할 루트 폴더 지정  \n",
    "search_root = \"D:\\\\078.스마트 제조 시설 안전 감시를 위한 데이터\\\\3.개방데이터\\\\1.데이터\\\\Validation\\\\01.원천데이터\\\\VS\\\\human-accident\\\\\"  \n",
    "\n",
    "##### 👉 찾기 시작!!!  \n",
    "root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\  \n",
    "dirs : ['bump', 'fall-down', 'fall-off', 'hit', 'jam', 'no-accident']  \n",
    "files : []  \n",
    "\n",
    "##### 👉 dirs에 하나씩 들어가면서 찾습니다.  \n",
    "root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump  \n",
    "dirs : ['rgb']  \n",
    "files : []  \n",
    "\n",
    "\n",
    "root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\\rgb  \n",
    "dirs : ['human-accident_bump_rgb_0001_cctv1', 'human-accident_bump_rgb_0005_cctv2', 'human-accident_bump_rgb_0006_cctv2', 'human-accident_bump_rgb_0021_cctv2', 'human-accident_bump_rgb_0047_cctv3', 'human-accident_bump_rgb_0049_cctv4', 'human-accident_bump_rgb_0053_cctv4', 'human-accident_bump_rgb_0055_cctv1', 'human-accident_bump_rgb_0067_cctv3', 'human-accident_bump_rgb_0077_cctv1', 'human-accident_bump_rgb_0081_cctv2', 'human-accident_bump_rgb_0084_cctv3', 'human-accident_bump_rgb_1365_cctv4', 'human-accident_bump_rgb_1379_cctv3', 'human-accident_bump_rgb_1382_cctv3', 'human-accident_bump_rgb_1388_cctv1',]  \n",
    "files : []  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664927c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os   # 🔥 특정 디렉토리에 있는 데이터 조작을 위함. (매우 유용하게 사용됨.)\n",
    "# import cv2\n",
    "\n",
    "# # 1. 탐색할 루트 폴더 (복잡한 데이터 폴더)\n",
    "# search_root = \"D:\\\\078.스마트 제조 시설 안전 감시를 위한 데이터\\\\3.개방데이터\\\\1.데이터\\\\Validation\\\\01.원천데이터\\\\VS\\\\human-accident\\\\\"\n",
    "\n",
    "# # 2. 변환 후 저장할 폴더 지정\n",
    "# save_root = \"./data/test_output_videos\"\n",
    "# os.makedirs(save_root, exist_ok=True)  # save_root가 이미 만들어져있다면 더 이상 만들지 않습니다.\n",
    "\n",
    "# # 3. 특정 확장자(.mp4) 파일 탐색 및 변환\n",
    "# for root, dirs, files in os.walk(search_root):\n",
    "#     # print(f\"\\n\\nroot : {root}\")\n",
    "#     # print(f\"dirs : {dirs}\")\n",
    "#     # print(f\"files : {files}\")\n",
    "#     # ------<출력내용 파악하기>------\n",
    "#     # root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\\n",
    "#     # dirs : ['bump', 'fall-down', 'fall-off', 'hit', 'jam', 'no-accident']\n",
    "#     # files : []\n",
    "#     # root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\n",
    "#     # dirs : ['rgb']\n",
    "#     # files : []\n",
    "#     # root : D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\\rgb\n",
    "#     # dirs : ['human-accident_bump_rgb_0001_cctv1', 'human-accident_bump_rgb_0005_cctv2', 'human-accident_bump_rgb_0006_cctv2', 'human-accident_bump_rgb_0021_cctv2', 'human-accident_bump_rgb_0047_cctv3', 'human-accident_bump_rgb_0049_cctv4', 'human-accident_bump_rgb_0053_cctv4', 'human-accident_bump_rgb_0055_cctv1', 'human-accident_bump_rgb_0067_cctv3', 'human-accident_bump_rgb_0077_cctv1', 'human-accident_bump_rgb_0081_cctv2', 'human-accident_bump_rgb_0084_cctv3', 'human-accident_bump_rgb_0091_cctv4', 'human-accident_bump_rgb_0121_cctv1', 'human-accident_bump_rgb_0130_cctv3', 'human-accident_bump_rgb_0138_cctv1', 'human-accident_bump_rgb_0139_cctv1', 'human-accident_bump_rgb_0146_cctv2', 'human-accident_bump_rgb_0161_cctv1', 'human-accident_bump_rgb_0191_cctv3', 'human-accident_bump_rgb_0193_cctv3', 'human-accident_bump_rgb_0198_cctv4', 'human-accident_bump_rgb_0205_cctv2', 'human-accident_bump_rgb_0206_cctv2', 'human-accident_bump_rgb_0215_cctv4', 'human-accident_bump_rgb_0226_cctv2', 'human-accident_bump_rgb_0285_cctv2', 'human-accident_bump_rgb_0290_cctv2', 'human-accident_bump_rgb_0291_cctv3', 'human-accident_bump_rgb_0295_cctv3', 'human-accident_bump_rgb_0299_cctv4', 'human-accident_bump_rgb_0300_cctv4', 'human-accident_bump_rgb_0307_cctv1', 'human-accident_bump_rgb_0310_cctv2', 'human-accident_bump_rgb_0311_cctv2', 'human-accident_bump_rgb_0320_cctv4', 'human-accident_bump_rgb_0322_cctv4', 'human-accident_bump_rgb_0329_cctv2', 'human-accident_bump_rgb_0345_cctv1', 'human-accident_bump_rgb_0374_cctv2', 'human-accident_bump_rgb_0380_cctv3', 'human-accident_bump_rgb_0381_cctv4', 'human-accident_bump_rgb_0394_cctv2', 'human-accident_bump_rgb_0396_cctv2', 'human-accident_bump_rgb_0424_cctv3', 'human-accident_bump_rgb_0426_cctv4', 'human-accident_bump_rgb_0434_cctv1', 'human-accident_bump_rgb_0443_cctv3', 'human-accident_bump_rgb_0450_cctv4', 'human-accident_bump_rgb_0453_cctv1', 'human-accident_bump_rgb_0492_cctv1', 'human-accident_bump_rgb_0507_cctv4', 'human-accident_bump_rgb_0508_cctv4', 'human-accident_bump_rgb_0511_cctv1', 'human-accident_bump_rgb_0518_cctv2', 'human-accident_bump_rgb_0560_cctv2', 'human-accident_bump_rgb_0561_cctv3', 'human-accident_bump_rgb_0569_cctv1', 'human-accident_bump_rgb_0575_cctv2', 'human-accident_bump_rgb_0583_cctv4', 'human-accident_bump_rgb_0585_cctv4', 'human-accident_bump_rgb_0599_cctv3', 'human-accident_bump_rgb_0600_cctv3', 'human-accident_bump_rgb_0603_cctv4', 'human-accident_bump_rgb_0614_cctv2', 'human-accident_bump_rgb_0617_cctv3', 'human-accident_bump_rgb_0628_cctv1', 'human-accident_bump_rgb_0640_cctv3', 'human-accident_bump_rgb_0661_cctv4', 'human-accident_bump_rgb_0664_cctv4', 'human-accident_bump_rgb_0710_cctv1', 'human-accident_bump_rgb_0729_cctv4', 'human-accident_bump_rgb_0732_cctv1', 'human-accident_bump_rgb_0741_cctv3', 'human-accident_bump_rgb_0759_cctv4', 'human-accident_bump_rgb_0778_cctv4', 'human-accident_bump_rgb_0782_cctv4', 'human-accident_bump_rgb_0786_cctv1', 'human-accident_bump_rgb_0793_cctv3', 'human-accident_bump_rgb_0805_cctv1', 'human-accident_bump_rgb_0817_cctv3', 'human-accident_bump_rgb_0824_cctv1', 'human-accident_bump_rgb_0827_cctv1', 'human-accident_bump_rgb_0829_cctv2', 'human-accident_bump_rgb_0834_cctv3', 'human-accident_bump_rgb_0839_cctv4', 'human-accident_bump_rgb_0864_cctv4', 'human-accident_bump_rgb_0865_cctv4', 'human-accident_bump_rgb_0882_cctv4', 'human-accident_bump_rgb_0893_cctv2', 'human-accident_bump_rgb_0908_cctv1', 'human-accident_bump_rgb_0920_cctv3', 'human-accident_bump_rgb_0955_cctv1', 'human-accident_bump_rgb_0979_cctv1', 'human-accident_bump_rgb_0987_cctv2', 'human-accident_bump_rgb_1000_cctv1', 'human-accident_bump_rgb_1003_cctv2', 'human-accident_bump_rgb_1010_cctv3', 'human-accident_bump_rgb_1025_cctv2', 'human-accident_bump_rgb_1034_cctv4', 'human-accident_bump_rgb_1037_cctv4', 'human-accident_bump_rgb_1038_cctv1', 'human-accident_bump_rgb_1044_cctv2', 'human-accident_bump_rgb_1063_cctv2', 'human-accident_bump_rgb_1067_cctv2', 'human-accident_bump_rgb_1082_cctv1', 'human-accident_bump_rgb_1098_cctv1', 'human-accident_bump_rgb_1108_cctv3', 'human-accident_bump_rgb_1133_cctv3', 'human-accident_bump_rgb_1141_cctv1', 'human-accident_bump_rgb_1149_cctv2', 'human-accident_bump_rgb_1151_cctv2', 'human-accident_bump_rgb_1182_cctv4', 'human-accident_bump_rgb_1183_cctv4', 'human-accident_bump_rgb_1189_cctv2', 'human-accident_bump_rgb_1193_cctv2', 'human-accident_bump_rgb_1223_cctv4', 'human-accident_bump_rgb_1233_cctv2', 'human-accident_bump_rgb_1238_cctv3', 'human-accident_bump_rgb_1245_cctv1', 'human-accident_bump_rgb_1248_cctv1', 'human-accident_bump_rgb_1259_cctv3', 'human-accident_bump_rgb_1283_cctv4', 'human-accident_bump_rgb_1320_cctv3', 'human-accident_bump_rgb_1325_cctv4', 'human-accident_bump_rgb_1331_cctv1', 'human-accident_bump_rgb_1332_cctv1', 'human-accident_bump_rgb_1361_cctv3', 'human-accident_bump_rgb_1365_cctv4', 'human-accident_bump_rgb_1379_cctv3', 'human-accident_bump_rgb_1382_cctv3', 'human-accident_bump_rgb_1388_cctv1', 'human-accident_bump_rgb_1394_cctv2', 'human-accident_bump_rgb_1409_cctv1', 'human-accident_bump_rgb_1412_cctv1', 'human-accident_bump_rgb_1419_cctv3', 'human-accident_bump_rgb_1422_cctv3', 'human-accident_bump_rgb_1428_cctv3', 'human-accident_bump_rgb_1430_cctv3', 'human-accident_bump_rgb_1436_cctv1']\n",
    "#     # files : []\n",
    "\n",
    "#     for file in files:  # 찾았을 때 files에 있는 file이 존재한다면 for문으로 하나씩 확인한다.\n",
    "#         if file.lower().endswith(\".mp4\"):  # file이름을 모두 소문자로 바꿔서 끝자리가 mp4로 끝난다면,\n",
    "#             print(f\"\\n\")\n",
    "#             input_path = os.path.join(root, file)   #\n",
    "#             print(f\"👉 input_path 확인: {input_path}\")\n",
    "#             # 찾은 mp4를 다시 경로로 만들어서 input_path 변수에 저장.\n",
    "\n",
    "#             # ❤️ 지금까지 특정 데이터가 존재하는 디렉토리를 읽어들여서 특정 파일을 찾는 코드를 구현함.\n",
    "#             # ============================================================\n",
    "#             # ❤️ 지금부터는 mp4 파일을 변환 및 저장하겠음.\n",
    "\n",
    "#             # 비디오 캡처 열기 (동영상 객체 생성)\n",
    "#             cap = cv2.VideoCapture(input_path)\n",
    "#             if not cap.isOpened():  # 만약 해당 비디오 캡쳐를 열 수 없다면,\n",
    "#                 print(f\"열 수 없음: {input_path}\") # 이 path를 열수 없다는 안내 출력\n",
    "#                 continue                         # 밑에 코드를 실행하지 않고, 다음으로 넘어갑니다.\n",
    "\n",
    "#             # 영상 속성 가져오기\n",
    "#             fps = int(cap.get(cv2.CAP_PROP_FPS))  # 동영상의 fps를 확인\n",
    "#             print(f\"fps : {fps}\")\n",
    "#             fps_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 총 프레임의 수\n",
    "#             print(f\"fps_total : {fps_total}\")\n",
    "#             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 동영상의 넓이 확인\n",
    "#             print(f\"width : {width}\")\n",
    "#             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 동영상의 높이 확인\n",
    "#             print(f\"height : {height}\")\n",
    "#             size = (width, height)  # width, height (튜플형태로 만듬)\n",
    "#             print(f\"size : {size}\")\n",
    "\n",
    "#             # 저장할 파일명 변수 만들기(avi)\n",
    "#             base_name = os.path.splitext(file)[0] # os.path.splitext() 파일 경로에서 확장자를 분리 / 파이썬 표준 라이브러리 함수\n",
    "#             print(f\"[변수명] base_name : {base_name}\")\n",
    "#             output_path = os.path.join(save_root, base_name + \".avi\")\n",
    "#             print(f\"[변수명] output_path : {output_path}\")\n",
    "\n",
    "#             # fourcc 코덱 정의 (XVID, DIVX 등 가능)\n",
    "#             fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "#             # DIVX 인코딩 방법 정의\n",
    "#             out = cv2.VideoWriter(output_path, fourcc, fps, size, isColor=True)\n",
    "\n",
    "#             # 프레임 읽고 저장\n",
    "#             print(f\"변환 시작: {input_path} -> {output_path}\")\n",
    "#             while True:\n",
    "#                 ret, frame = cap.read()  # 동영상 파일에서 프레임 읽기\n",
    "#                 if not ret:\n",
    "#                     break\n",
    "#                 out.write(frame)  # 프레임 그대로 저장\n",
    "#                 # imshow(제목, 표시하고자하는 img) 를 지정하여 화면에 표시\n",
    "#                 # cv2.imshow(decided_path, img)\n",
    "#                 # cv2.waitKey(25)  # 25ms 지연(40fps로 가정)\n",
    "#                 print(f\"정상적으로 저장이 완료되었습니다.\")\n",
    "\n",
    "#             cap.release()  # 자원 반납 (메모리 반납)\n",
    "#             out.release()  # 자원 반납 (메모리 반납)\n",
    "#             cv2.destroyAllWindows()  # 재생이 끝난 후 imshow 창 모두 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b3e58",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 🟡 2-3. [추가] 클래스별로 폴더를 만들고 넣어야 합니다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddf907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----<현재 Folder 확인>----\n",
      "👉 relative_path 확인: bump\\rgb\\human-accident_bump_rgb_0001_cctv1\n",
      "👉 class_name 확인: bump\n",
      "👉 class_dir 확인: ./data/safety-data/human-accident\\bump 폴더를 생성하였습니다.\n",
      "---<파일 path 확인>----\n",
      "👉 input_path 확인: D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\\rgb\\human-accident_bump_rgb_0001_cctv1\\human-accident_bump_rgb_0001_cctv1.mp4\n",
      "정상적으로 저장이 완료되었습니다.\n",
      "\n",
      "----<현재 Folder 확인>----\n",
      "👉 relative_path 확인: bump\\rgb\\human-accident_bump_rgb_0005_cctv2\n",
      "👉 class_name 확인: bump\n",
      "👉 class_dir 확인: ./data/safety-data/human-accident\\bump 폴더를 생성하였습니다.\n",
      "---<파일 path 확인>----\n",
      "👉 input_path 확인: D:\\078.스마트 제조 시설 안전 감시를 위한 데이터\\3.개방데이터\\1.데이터\\Validation\\01.원천데이터\\VS\\human-accident\\bump\\rgb\\human-accident_bump_rgb_0005_cctv2\\human-accident_bump_rgb_0005_cctv2.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# 프레임 읽고 저장\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# print(f\"변환 시작: {input_path} -> {output_path}\")\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 동영상 파일에서 프레임 읽기\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os  # 🔥 특정 디렉토리에 있는 데이터 조작을 위함. (매우 유용하게 사용됨.)\n",
    "import cv2\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. 탐색할 루트 폴더 (복잡한 데이터 폴더)\n",
    "search_root = \"D:\\\\078.스마트 제조 시설 안전 감시를 위한 데이터\\\\3.개방데이터\\\\1.데이터\\\\Validation\\\\01.원천데이터\\\\VS\\\\human-accident\\\\\"\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. 변환 후 저장할 폴더 지정\n",
    "save_root = \"./data/safety-data/human-accident\"\n",
    "os.makedirs(save_root, exist_ok=True)  \n",
    "# save_root가 이미 만들어져있다면 더 이상 만들지 않습니다.\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. 특정 확장자(.mp4) 파일 탐색(os 활용) 및 cv2를 통한 avi 변환\n",
    "count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(search_root):\n",
    "\n",
    "    for file in files:  \n",
    "        if file.lower().endswith(\".mp4\"):\n",
    "            # ============================================================\n",
    "            print(f\"\\n----<현재 Folder 확인>----\")\n",
    "            # 클래스 이름 추출 (❤️ 내가 정한 루트 폴더 바로 아래의 폴더들이 class 폴더들이라고 가정할 때만 가능한 코드임.)\n",
    "            # os.path.relpath(경로1, 경로2) 는 경로2에 대한 경로1의 상대 경로를 출력해준다. 경로2가 없으면 현재 작업 폴더가 기준 경로가 된다.\n",
    "            relative_path = os.path.relpath(root, search_root) # 상대경로를 변수에 저장. 🔥os.relpath\n",
    "            print(f\"👉 relative_path 확인: {relative_path}\")\n",
    "\n",
    "            # os.sep = 해당 OS별 경로 구분자를 통해 split하여 list를 반환하고, 이 list의 첫번째 값을 가져온다.\n",
    "            class_name = relative_path.split(os.sep)[0]  # 🔥os.sep (seperator)\n",
    "            print(f\"👉 class_name 확인: {class_name}\")\n",
    "\n",
    "            # 내가 저장할 save_root 아래에 class 폴더까지의 경로를 만듭니다.\n",
    "            class_dir = os.path.join(save_root, class_name)\n",
    "            # 내가 저장할 save_root 아래에 class 폴더를 만들어줍니다.\n",
    "            os.makedirs(class_dir, exist_ok=True)   # 클래스별 폴더 생성\n",
    "            print(f\"👉 class_dir 확인: {class_dir} 폴더를 생성하였습니다.\")\n",
    "\n",
    "            print(f\"---<파일 path 확인>----\")\n",
    "            # 찾은 mp4를 다시 경로로 만들어서 input_path 변수에 저장.\n",
    "            input_path = os.path.join(root, file)\n",
    "            print(f\"👉 input_path 확인: {input_path}\")\n",
    "\n",
    "            # ❤️ 지금까지 특정 데이터가 존재하는 디렉토리를 읽어들이고, 클래스별로 폴더를 구분하였음.\n",
    "            # ============================================================\n",
    "            # ❤️ 지금부터는 mp4 동영상을 찾아서 avi로 변환하여, 클래스 폴더별로 저장할 것임.\n",
    "\n",
    "            # 비디오 캡처 열기 (동영상 객체 생성)\n",
    "            cap = cv2.VideoCapture(input_path)\n",
    "            if not cap.isOpened():  # 만약 해당 비디오 캡쳐를 열 수 없다면,\n",
    "                print(f\"열 수 없음: {input_path}\")  # 이 path를 열수 없다는 안내 출력\n",
    "                continue  # 밑에 코드를 실행하지 않고, 다음으로 넘어갑니다.\n",
    "\n",
    "            # 영상 속성 가져오기\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))  # 동영상의 fps를 확인\n",
    "            # print(f\"fps : {fps}\")\n",
    "            fps_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 총 프레임의 수\n",
    "            # print(f\"fps_total : {fps_total}\")\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 동영상의 넓이 확인\n",
    "            # print(f\"width : {width}\")\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 동영상의 높이 확인\n",
    "            # print(f\"height : {height}\")\n",
    "            size = (width, height)  # width, height (튜플형태로 만듬)\n",
    "            # print(f\"size : {size}\")\n",
    "\n",
    "            # 저장할 파일명 변수 만들기(avi)\n",
    "            base_name = os.path.splitext(file)[0] # os.path.splitext() 파일 경로에서 확장자를 분리 / 파이썬 표준 라이브러리 함수\n",
    "            # print(f\"[변수명] base_name : {base_name}\")\n",
    "            output_path = os.path.join(class_dir, base_name + \".avi\")\n",
    "            # print(f\"[변수명] output_path : {output_path}\")\n",
    "\n",
    "            # fourcc 코덱 정의 (XVID, DIVX 등 가능)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "            # DIVX 인코딩 방법 정의\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, size, isColor=True)\n",
    "\n",
    "            # 프레임 읽고 저장\n",
    "            # print(f\"변환 시작: {input_path} -> {output_path}\")\n",
    "            while True:\n",
    "                ret, frame = cap.read()  # 동영상 파일에서 프레임 읽기\n",
    "                if not ret:\n",
    "                    break\n",
    "                out.write(frame)  # 프레임 그대로 저장\n",
    "                # imshow(제목, 표시하고자하는 img) 를 지정하여 화면에 표시\n",
    "                # cv2.imshow(decided_path, img)\n",
    "                # cv2.waitKey(25)  # 25ms 지연(40fps로 가정)\n",
    "\n",
    "            cap.release()  # 자원 반납 (메모리 반납)\n",
    "            out.release()  # 자원 반납 (메모리 반납)\n",
    "            print(f\"정상적으로 저장이 완료되었습니다.\")\n",
    "            count += 1\n",
    "            # cv2.destroyAllWindows()  # 재생이 끝난 후 imshow 창 모두 닫기\n",
    "\n",
    "print(f\"❤️ 변환 수: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
