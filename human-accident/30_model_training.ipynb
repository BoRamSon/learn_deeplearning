{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd692c70",
   "metadata": {},
   "source": [
    "# 🟩 Model Selection & Design  \n",
    "\n",
    "### ❤️ 지금까지 해온 것 정리하기  \n",
    "1. 처음 목표를 정했다. = **산업안전**  \n",
    "\n",
    "2. 관련 데이터셋을 찾았다. = **스마트 제조 시설 안전 감시를 위한 데이터**  \n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=1&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%A0%9C%EC%A1%B0&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&aihubDataSe=data&dataSetSn=71679  \n",
    "\n",
    "3. 데이터셋을 어떤 `모델`로 학습할 것인지 정했다. = **cnn-lstm**  \n",
    "    - https://github.com/pranoyr/cnn-lstm  \n",
    "\n",
    "4. 해당 모델이 학습할 수 있는 형태로 데이터셋을 **`전처리`** 해준다.  \n",
    "    - https://github.com/pranoyr/cnn-lstm/blob/master/dataset.py  \n",
    "\n",
    "5. https://github.com/pranoyr/cnn-lstm/blob/master/dataset.py 코드 파악 완료  \n",
    "\n",
    "6. 이제 모델을 활용해 학습을 해야한다!!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112478a",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 🟩 Model Training - AI에 물어볼 Script  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19568218",
   "metadata": {},
   "source": [
    "## 🟢 1. 본격적으로 training 들어가기  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485a09f",
   "metadata": {},
   "source": [
    "\n",
    "1. 나는 제조업에서 발생하는 안전사고를 사전에 차단하기 위해 컴퓨터 비전 기술을 개발하려고 합니다.  \n",
    "    - 개발환경  \n",
    "        - MacOS M1 pro  \n",
    "        - astral uv packag 관리자 사용중  \n",
    "            - 현재 설치된 라이브러리 (현재 다 설치되어 있음.)  \n",
    "                - [project]  \n",
    "                    version = \"0.1.0\"  \n",
    "                    readme = \"README.md\"  \n",
    "                    requires-python = \">=3.11\"  \n",
    "\n",
    "                    dependencies = [  \n",
    "                        \"matplotlib>=3.10.6\",  \n",
    "                        \"numpy>=2.3.2\",  \n",
    "                        \"torch\",  \n",
    "                        \"torchvision\",  \n",
    "                        \"torchaudio\",  \n",
    "                        \"python-dotenv>=1.1.1\",  \n",
    "                        \"opencv-python>=4.11.0.86\",  \n",
    "                        \"tensorflow>=2.20.0\",  \n",
    "                        \"nbconvert>=7.16.6\",  \n",
    "                        \"nbformat>=5.10.4\",  \n",
    "                        \"seaborn>=0.13.2\",  \n",
    "                    ]  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-cu128\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cu128\"  \n",
    "                    explicit = true  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-cpu\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cpu\"  \n",
    "                    explicit = true  \n",
    "\n",
    "                    [[tool.uv.index]]  \n",
    "                    name = \"pytorch-mps\"  \n",
    "                    url = \"https://download.pytorch.org/whl/cpu\"  \n",
    "                    explicit = true  \n",
    "\n",
    "\n",
    "                    [tool.uv.sources]  \n",
    "                    torch = [  \n",
    "                        # Windows/Linux → CUDA 12.8 wheel 인덱스  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        # macOS → CPU wheel (MPS 지원 포함)  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "                    torchvision = [  \n",
    "                        # torchvision도 torch와 동일한 인덱스를 사용하도록 설정  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "                    torchaudio = [  \n",
    "                        # torchaudio도 torch와 동일한 인덱스를 사용하도록 설정  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'win32' and platform_machine == 'AMD64'\" },  \n",
    "                        { index = \"pytorch-cu128\", marker = \"sys_platform == 'linux' and platform_machine == 'x86_64'\" },  \n",
    "                        { index = \"pytorch-mps\", marker = \"sys_platform == 'darwin'\" },  \n",
    "                    ]  \n",
    "\n",
    "<br>\n",
    "\n",
    "2. AI허브 데이터셋 = 스마트 제조 시설 안전 감시를 위한 데이터  \n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=1&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%A0%9C%EC%A1%B0&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&aihubDataSe=data&dataSetSn=71679  \n",
    "    - 위 데이터셋을 가지고 전처리를 하였으며,  \n",
    "    - 여기까지 코드를 만들었어요~  \n",
    "        ```python\n",
    "            from torch.utils.data import DataLoader  # 데이터로더를 만들기 위함  \n",
    "\n",
    "            # 이미지에 대한 경로, 일괄적으로 적용할 전처리 이 2가지를 인수로 넣어줌.  \n",
    "            dataset = CustomData(video_path, transform)  \n",
    "\n",
    "\n",
    "            dataloader = DataLoader(  \n",
    "                dataset=dataset,  \n",
    "                batch_size=8,  # 컴퓨터사양에 따라서 메모리가 처리할 수 있는 양을 정해줘야합니다.  \n",
    "                # 2n승 으로 늘려주는 편이다. 2,4,8,16,32,64,128,~~256,  \n",
    "                # 정해주고, 메모리가 감당이 가능한지 확인해봐야합니다.  \n",
    "                shuffle=True,  \n",
    "                drop_last=False,  # 마지막에 남는 데이터도 사용합니다. (False: 버리지 않음)  \n",
    "            )  \n",
    "        ```\n",
    "\n",
    "<br>\n",
    "\n",
    "3. 내가 사용할 모델 https://github.com/pranoyr/cnn-lstm 에 대한 코드 파악을 하고, 나의 폴더 내에 통째로 clone을 해둔 상태입니다.  \n",
    "\n",
    "<br>\n",
    "\n",
    "4. 현재 폴더 구조 정보 (영상이 담겨진 폴더가 class이며, 각 영상의 파일명이 라벨로 사용됩니다.)  \n",
    "    .venv  \n",
    "    pyproject.toml  \n",
    "    uv.lock  \n",
    "    human-accident/  \n",
    "    ├── data  \n",
    "    │   ├── safety-data             \n",
    "    │   │   └── human-accident      # AI허브에서 다운로드하여 전처리한 데이터  \n",
    "    ├── cnn-lstm/                   # pranoyr/cnn-lstm 저장소 clone  \n",
    "    │   ├── datasets/  \n",
    "    │   │   └── ucf101.py           # UCF101 데이터셋 로직 정의  \n",
    "    │   ├── models/  \n",
    "    │   │   └── cnnlstm.py          # CNN-LSTM 모델 아키텍처 정의  \n",
    "    │   ├── customdata.py           # 🚨 human-accident 데이터에 맞춘 커스텀테이터셋 class  \n",
    "    │   ├── dataloader.py           # 🚨 human-accident 데이터를 컨트롤 할 수 있는 데이터 로더를 만들어놓음.  \n",
    "    │   ├── main.py                 # 전체 학습 파이프라인 실행  \n",
    "    │   ├── opts.py                 # 커맨드라인 옵션 정의  \n",
    "    │   ├── dataset.py              # 데이터셋 선택 및 생성  \n",
    "    │   ├── model.py                # 모델 선택 및 생성  \n",
    "    │   ├── train.py                # 1 에폭(epoch) 학습 로직  \n",
    "    │   ├── validation.py           # 1 에폭(epoch) 검증 로직  \n",
    "    │   ├── mean.py                 # 데이터 정규화를 위한 평균값 계산  \n",
    "    │   ├── spatial_transforms.py   # 공간적 데이터 증강/변환  \n",
    "    │   ├── temporal_transforms.py  # 시간적 데이터 증강/변환  \n",
    "    │   ├── target_transforms.py    # 라벨 데이터 변환  \n",
    "    │   └── utils.py                # 유틸리티 함수  \n",
    "\n",
    "<br>\n",
    "\n",
    "5. 저는 이제 학습시킬 준비가 되었어요~  customdata.py, dataloader.py 파일을 main.py에 잘 넣어주면 된단 말입니다. 물론 customdata.py는 class이기 때문에 dataloader.py에서 잘 쓰기만 하면 되구요.  \n",
    "\n",
    "6. dataloader.py는 함수화 시켜서 뭔가 반환을 해줘야하는데 뭘 반환해줘야 했지? 까먹음... 맞게 고쳐봐  \n",
    "\n",
    "7. 다 끝나면 dataloader만 main.py에 잘 넣으면 되겠네요. 학습까지 진행할 수 있도록 만들어주세요.  \n",
    "\n",
    "8. 모든 내용은 한국어로 진행합니다. 그리고 진행한 상황들은 모두 단계별로 Record_과정 폴더 내에 markdown 파일을 만들어서 기록해주세요!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeea73c",
   "metadata": {},
   "source": [
    "### ⚫ 해보자  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Linux / WSL / Windows PowerShell(인스톨된 경우)) 확인\n",
    "# nvidia-smi\n",
    "\n",
    "# FFmpeg (비디오 → 프레임 변환에 필요)\n",
    "# winget install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57edfb1",
   "metadata": {},
   "source": [
    "## 🟢 2. 나는 지금 21_my_custum_dataset.ipynb 파일에서 customdata.py, dataloader.py 분리 했는데  \n",
    "\n",
    "- ai허브에서 가져온 data/safety-data  \n",
    "- 내가 전처리 가능하게 만드는 customdata.py, dataloader.py 파일 2개  \n",
    "- cnn-lstm 모델로 학습을 시켜야하는건데...  \n",
    "\n",
    "customdata.py, dataloader.py 얘네들 위치를 어디에 둬야하냐고  \n",
    "\n",
    "= cnn-lstm 폴더에 넣어야지~~  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531e9fb",
   "metadata": {},
   "source": [
    "## 🟢 3. 이제 data는 data 폴더에 있고, cnn-lstm 내에서 처리하면 됩니다.  \n",
    "\n",
    "### 이제는 main에서 customdata.py, dataloader.py을 건들 수 있도록 만들어야 합니다.  \n",
    "\n",
    "- 현재 main.py를 건드려서 하던지  \n",
    "- 새로운 나만의 main.py를 만들어서 하던지  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
