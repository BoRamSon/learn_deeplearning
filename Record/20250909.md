## ğŸŸ¢ **[Dataset ì´í•´í•˜ê¸°]** Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ì„œ ë‚´ê°€ ì§ì ‘ __len__ê³¼ __getitem__ì„ ì •ì˜  


```python
import torch #í›ˆë ¨
from torch.utils.data import Dataset, DataLoader #ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ë§Œë“¤ê¸° ìœ„í•¨

import os #ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´
import cv2 # ì‹œê°í™” í•´ì„œ í‘œí˜„í•˜ê¸° ìœ„í•¨
```


```python
# Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ì„œ ìƒˆë¡œìš´ Datasetì„ ì •ì˜

# __í•¨ìˆ˜__ : ë˜ë” í•¨ìˆ˜
class SimpleDataset(Dataset):
    # ì´ í´ë˜ìŠ¤ì˜ ê°ì²´ê°€ ìƒì„±ë˜ë©´ ë¬´ì¡°ê±´ __init__ í•¨ìˆ˜ê°€ ë™ì‘í•˜ê²Œ ë¨
    # ê¸°ì´ˆ ë°ì´í„°, í•¨ìˆ˜ ë™ì‘í•˜ë„ë¡ ì—°ê²°
    def __init__(self, t):
        self.t = t

    # ë°ì´í„°ì…‹ì˜ ê¸¸ì´ ë°˜í™˜
    # íŒŒì´í† ì¹˜ê°€ í›ˆë ¨ì„ í•  ë•Œ len() -> ë°°ì¹˜ì‚¬ì´ì¦ˆ ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë°ì´í„°ì…‹ì´ ë‚¨ì•„ìˆëŠ” ì§€ ì²´í¬í•  ë•Œ ì”€
    #    len(dataset) ì„ ì‹¤í–‰í•˜ë©´ ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë¨
    def __len__(self):
        return self.t

    # ë°ì´í„° + ë¼ë²¨ -> í•œ ìŒì„ ë½‘ëŠ” ë° ì”€
    # idx(index) = ëª‡ ë²ˆì§¸ ë°ì´í„°?
    #    dataset[0] ì²˜ëŸ¼ íŠ¹ì • ë°ì´í„°ë¥¼ êº¼ë‚¼ ë•Œ ì‹¤í–‰ë¨
    def __getitem__(self, idx):
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ LongTensor(ì •ìˆ˜í˜• í…ì„œ)ë¡œ ë°˜í™˜
        return torch.LongTensor([idx])
```

Dataset í´ë˜ìŠ¤  
   â”‚  
   â”œâ”€â”€ __init__(ë°ì´í„° ì¤€ë¹„)  
   â”‚  
   â”œâ”€â”€ __len__() â†’ ë°ì´í„° ê°œìˆ˜ ì•Œë ¤ì¤Œ  
   â”‚  
   â””â”€â”€ __getitem__(i) â†’ ië²ˆì§¸ ë°ì´í„° êº¼ë‚´ì¤Œ  



```python
# SimpleDataset í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ì´ 7ê°œì˜ ë°ì´í„°ê°€ ìˆëŠ” ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.
dataset = SimpleDataset(t=7)

dataset.__len__()
```




    7




```python
len(dataset)  # 7 (ë°ì´í„° ê°œìˆ˜)
```




    7




```python
dataset.__getitem__(3)
```




    tensor([3])




```python
dataset[3]  # tensor([3])  (ì„¸ ë²ˆì§¸ ë°ì´í„° êº¼ëƒ„)
```




    tensor([3])




```python
# ğŸ†˜ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ ë¬´í•œëŒ€ë¡œ ë‚˜ì˜¤ëŠ” ì´ìœ ë¥¼ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
# for i, data in enumerate(dataset):
#     print(f"{i}ë²ˆì§¸ : {data}")
```


```python
type(dataset[3])
```




    torch.Tensor



<br>

## ğŸŸ¢ **[DataLoader ì´í•´í•˜ê¸°]** - ë°ì´í„°ì…‹ì„ í›ˆë ¨ì— ì‚¬ìš©í•˜ê¸° ì¢‹ê²Œ ë§Œë“¤ê¸°  

ë§Œì•½ ë°ì´í„°ê°€ 100ë§Œ ê°œë¼ë©´, ì´ê±¸ í•œ ë²ˆì— ì²˜ë¦¬í•˜ê¸°ëŠ” ì–´ë µë‹¤. ê·¸ë˜ì„œ DataLoaderê°€ batch_sizeë§Œí¼ ë°ì´í„°ë¥¼ ì˜ë¼ì„œ ì¡°ê¸ˆì”© ëª¨ë¸ì— ì „ë‹¬í•´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.  


```python
# ì´ ë°ì´í„°ì…‹ì„ í›ˆë ¨ì—ì„œ ì–´ë–»ê²Œ í™œìš©í•  ê²ƒì¸ê°€?
dataloader = DataLoader(
    dataset=dataset,    # ì–´ë–¤ ë°ì´í„°ì…‹ì„ í›ˆë ¨ì— ì“¸ ê±°ë‹ˆ?
    batch_size=2,       # ë°ì´í„°ì…‹ì„ ìª¼ê°œ ë°°ì¹˜ë¡œ ë§Œë“¦
    shuffle=True,       # ë°ì´í„°ì…‹ì„ ì„ì–´ì£¼ëŠ”(ëœë¤)
    drop_last=True,     # ë°°ì¹˜ì‚¬ì´ì¦ˆ ë§Œë“¤ê³  ë‚¨ì€ ë°ì´í„° ì“¸ê±°ì•¼? (True: ë²„ë¦¼)
    # ì´ 7ê°œì˜ ë°ì´í„°ë¥¼ batch_size 2ê°œì”© ì§ì§€ì–´ì¤¬ì„ ë•Œ, ë‚˜ë¨¸ì§€ 1ê°œê°€ ë‚¨ì€ ê²ƒì„ ë²„ë¦½ë‹ˆë‹¤.
)
```


```python
# DataLoaderê°€ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì£¼ëŠ”ì§€ í•™ìŠµê³¼ì •ì„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì˜ˆì‹œ

# epoch: ì „ì²´ ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚¬ìš©í•´ì„œ í•œ ë²ˆ í•™ìŠµí•˜ëŠ” ê³¼ì •

for e in range(3):  # ì´ 3ë²ˆì˜ epochë™ì•ˆ í›ˆë ¨ì„ í•œë‹¤.
    print(f"epoch : {e}")   # í˜„ì¬ ëª‡ë²ˆì§¸ epoch ì¸ì§€ ì¶œë ¥.

    for batch in dataloader:    # dataset ì „ì²´ë¥¼ ëŒë©´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.
        print(batch)
        print(type(batch))
        print("\n")
```

    epoch : 0
    tensor([[4],
            [2]])
    <class 'torch.Tensor'>
    
    
    tensor([[0],
            [6]])
    <class 'torch.Tensor'>
    
    
    tensor([[5],
            [3]])
    <class 'torch.Tensor'>
    
    
    epoch : 1
    tensor([[0],
            [4]])
    <class 'torch.Tensor'>
    
    
    tensor([[3],
            [6]])
    <class 'torch.Tensor'>
    
    
    tensor([[2],
            [5]])
    <class 'torch.Tensor'>
    
    
    epoch : 2
    tensor([[1],
            [4]])
    <class 'torch.Tensor'>
    
    
    tensor([[3],
            [0]])
    <class 'torch.Tensor'>
    
    
    tensor([[6],
            [5]])
    <class 'torch.Tensor'>
    
    
    

<br>

---
---
---

## ğŸŸ¢ **[CustomData ë§Œë“¤ê¸°]** - (ì˜ˆì‹œ) ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ì»¤ìŠ¤í…€í™” í•¨          
- ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ì²˜ë¦¬í•˜ëŠ” ë‚˜ë§Œì˜ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë§Œë“¤ê¸°!!!  

- ì´ë¯¸ì§€(0~255) ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„° -> ë”¥ëŸ¬ë‹ -> í…ì„œ í˜•íƒœë¡œ í‘œí˜„  
- í…ì„œ í˜•íƒœë¡œ ì´ë¯¸ì§€ë¥¼ í‘œí˜„í•´ ì¤˜ì•¼ í•¨.  


```python
# torchvision: PyTorchì—ì„œ ì´ë¯¸ì§€ ì²˜ë¦¬/ë°ì´í„°ì…‹ ê´€ë ¨ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
# ğŸ”¥transforms(ì „ì²˜ë¦¬): ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜, ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í…ì„œ(Tensor) í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë“± (ìë¥´ê¸°, íšŒì „, í…ì„œ ë³€í™˜, ì •ê·œí™” ë“±)
#                       ì´ë¯¸ì§€ ì „ì²˜ë¦¬(preprocessing) ê¸°ëŠ¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
from torchvision import transforms 

# PIL(Pillow) ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Image: íŒŒì´ì¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë‹¤ë£° ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.
from PIL import Image

import matplotlib.pyplot as plt # ì´ë¯¸ì§€ ì‹œê°í™”
```


```python
class CustomData(Dataset):
    def __init__(self, path, transform):
        self.image_path = path  # ì „ì²´ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì €ì¥
        # self.image_pathëŠ” ë³´í†µ ë¬¸ìì—´ ê²½ë¡œë“¤ì˜ ë¦¬ìŠ¤íŠ¸(ì˜ˆ: ["data/a.jpg","data/b.jpg", ...])
        # ë˜ëŠ” pathlib.Path ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. "path"ë¼ëŠ” ì´ë¦„ ë•Œë¬¸ì— í´ë” ê²½ë¡œ í•˜ë‚˜ë¥¼ ë°›ì„ ê²ƒì²˜ëŸ¼ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ
        # ì‹¤ì œë¡œëŠ” 'íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸'ì¸ì§€ 'í´ë” ê²½ë¡œ(ë‚´ë¶€ íƒìƒ‰ í•„ìš”)'ì¸ì§€ ëª…í™•íˆ í•´ì•¼ í•©ë‹ˆë‹¤.
        
        self.transform = transform  # ì´ë¯¸ì§€ì— ëŒ€í•´ ì¼ê´„ì ìœ¼ë¡œ ì ìš©í•  'ì „ì²˜ë¦¬'
        # transformì€ callable (ì˜ˆ: torchvision.transforms.Compose([...]))ì´ì–´ì•¼ í•˜ë©°,
        # ì…ë ¥ìœ¼ë¡œ PIL.Imageì„ ë°›ê³  ì¶œë ¥ìœ¼ë¡œ torch.Tensor(ë˜ëŠ” ë³€í™˜ëœ PIL/ndarray)ë¥¼ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.

    def __len__(self):
        # if (ì´ë¯¸ì§€ìˆ˜ == ë¼ë²¨ìˆ˜) return ì´ë¯¸ì§€ ìˆ˜
        return len(self.image_path)
        # __len__ì€ DataLoaderê°€ ì „ì²´ ë°ì´í„° ê°œìˆ˜ë¥¼ ì•Œê¸° ìœ„í•´ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # image_pathê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´(ì˜ˆ: glob ê²°ê³¼ê°€ ë¹ˆ ê²½ìš°) ì—¬ê¸°ì„œ ì—ëŸ¬ ë˜ëŠ” 0ì„ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



    # í…ì„œ í˜•íƒœë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ëŒë ¤ì¤Œ
    def __getitem__(self, idx):
        image = self.image_path[idx]
        # image ë³€ìˆ˜ëŠ” 'íŒŒì¼ ê²½ë¡œ ë¬¸ìì—´'ì…ë‹ˆë‹¤. ì£¼ì„ê³¼ í˜¼ë™í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤(ì´ë¯¸ì§€ê°€ ì•„ë‹˜).
        # ì˜ˆ: image == "data/img_001.jpg"

        image = Image.open(image)  # í•´ë‹¹ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ë¥¼ ì½ì–´ ì˜´
        # PIL.Image.openì€ íŒŒì¼ í•¸ë“¤ì„ ì—° ìƒíƒœë¡œ ë°˜í™˜(ì§€ì—° ë¡œë”©)í•©ë‹ˆë‹¤.
        # íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë‹«ìœ¼ë ¤ë©´ with Image.open(path) as img: ê°™ì€ ë¬¸ë²•ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        # ë˜í•œ, ì±„ë„ í†µì¼ì„ ìœ„í•´ .convert('RGB') í˜¹ì€ .convert('L')ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.

        if self.transform is not None:
            result = self.transform(image)
            # transformì´ ToTensor ë“±ì„ í¬í•¨í•˜ë©´ resultëŠ” torch.Tensor (C,H,W), dtype=float32, ê°’ë²”ìœ„ 0~1 ì´ ë©ë‹ˆë‹¤.
            # ì£¼ì˜: transformì´ PIL ì´ë¯¸ì§€ë¥¼ ë³€ê²½í•˜ê³  ë‹«ì§€ ì•Šìœ¼ë¯€ë¡œ ì´ë¯¸ì§€ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ì‹ ê²½ ì¨ì•¼ í•©ë‹ˆë‹¤.

        # csv,íŒŒì¼ ì´ë¦„ ë“±ì„ ì´ìš©í•´ì„œ ë°ì´í„°ì— ë§ëŠ” ë¼ë²¨ì„ ë°˜í™˜
        label = 1
        # í˜„ì¬ëŠ” í•˜ë“œì½”ë”©ëœ ë”ë¯¸ ë¼ë²¨(1)ì…ë‹ˆë‹¤. ì‹¤ì œ ì‘ì—…ì—ì„œëŠ”:
        # - íŒŒì¼ëª…/í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ì„ íŒŒì‹±í•˜ê±°ë‚˜,
        # - __init__ì— labels ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬í•˜ê±°ë‚˜,
        # - CSV íŒŒì¼ì„ ì½ì–´ ë¼ë²¨ ë§µì„ ë§Œë“¤ì–´ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        # ë¼ë²¨ì€ ì •ìˆ˜(int) ë˜ëŠ” torch.Tensor (ì˜ˆ: torch.tensor(label, dtype=torch.long)) ë¡œ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.

        return result, label
        # ì£¼ì˜: ë§Œì•½ self.transformì´ Noneì´ë©´ result ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•„ NameErrorê°€ ë‚©ë‹ˆë‹¤.
        # ë”°ë¼ì„œ transform None ì¼€ì´ìŠ¤ë¥¼ ë°˜ë“œì‹œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
```

<br><br>

---

## ğŸŸ¢ `CustomData`ì— ë„£ì„ `ì¸ìˆ˜` or `ë§¤ê°œë³€ìˆ˜` ì •ì˜í•˜ê¸°  


### ğŸŸ¡ **[transforms.Compose]** - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë°©ë²• ì •ì˜í•˜ê¸°  
- ë§Œë“¤ì–´ë†“ì€ CustomData classë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— ì „ì²˜ë¦¬ ë°©ë²•ì„ ì •ì˜í•˜ì.  
- ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ë„£ê¸° ì „ì—, ëª¨ë“  ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ê°™ê²Œ ë§Œë“¤ê³ , ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê³„ì‚°í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë°”ê¿”ì£¼ëŠ” ë“±ì˜ ì „ì²˜ë¦¬ ê³¼ì •ì´ í•„ìš”.  


```python
# ì—¬ëŸ¬ ê°€ì§€ ì „ì²˜ë¦¬ ë°©ë²•ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì£¼ëŠ” transforms.Composeë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

transform = transforms.Compose(
    [
        # 1. ì´ë¯¸ì§€ í¬ê¸° ì¡°ì ˆ: ëª¨ë“  ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ 224x224 í”½ì…€ë¡œ ë§ì¶¥ë‹ˆë‹¤.
        transforms.Resize((224, 224)),

        # 2. í…ì„œ(Tensor)ë¡œ ë³€í™˜: ì´ë¯¸ì§€ë¥¼ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìˆ«ì í–‰ë ¬(í…ì„œ)ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
        transforms.ToTensor(),

        # 3. ì •ê·œí™”(Normalize): ì´ë¯¸ì§€ì˜ í”½ì…€ ê°’ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ì—¬ ëª¨ë¸ì´ ë” ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.
        #    ì•„ë˜ meanê³¼ std ê°’ì€ ImageNet ë°ì´í„°ì…‹ì—ì„œ ë¯¸ë¦¬ ê³„ì‚°ëœ ê°’ìœ¼ë¡œ, ë³´í†µ ê·¸ëŒ€ë¡œ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)
```



### ğŸŸ¡ **[path ì§€ì •]** - (ì˜ˆì‹œ) ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°  (âŒ ë°ì´í„° ì—†ìŒ)  
- ğŸ”¥ pathë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´í•œë‹¤ëŠ” ê²ƒ  


```python
origin = "./data/safety-data/human-accident" # ì´ë¯¸ì§€ íŒŒì¼ì´ ëª¨ì—¬ìˆëŠ” directoryë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

os.listdir(origin)  # ğŸ”¥ originìœ¼ë¡œ ì •ì˜í•œ directoryì— ì¡´ì¬í•˜ëŠ” ê²ƒë“¤(ex. ì´ë¯¸ì§€ë“¤, ì˜ìƒë“¤, ë“±ë“±)ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤!!!
```




    ['bump', 'fall-down', 'fall-off', 'hit', 'jam', 'no-accident']




```python
# os.listdir(origin)ë¡œ ë§Œë“  ë¦¬ìŠ¤íŠ¸ì˜ ìš”ì†Œ í•˜ë‚˜ì”©ì„ ê°€ì ¸ì™€ origin path ë’¤ì— ë¶™ì—¬ì„œ ë‹¤ì‹œ listë¡œ ë§Œë“­ë‹ˆë‹¤.
image_list = [os.path.join(origin, x) for x in os.listdir(origin)]

# ë§Œë“  image_listì—ì„œ ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ í™•ì¸í•´ ë´…ë‹ˆë‹¤.
image_list[0]    #  =  './data/safety-data/human-accident\\bump'   ...  windowsì—ì„œëŠ” '/' ì´ê±°ë§ê³ , '\\'ì´ê±¸ë¡œ ì¨ì•¼ê² ìŠµë‹ˆë‹¤.
```




    './data/safety-data/human-accident\\bump'



<br><br>

---

## ğŸŸ¢ **[CustomData ì‚¬ìš©]** - (ì˜ˆì‹œ) ì´ë¯¸ì§€ë¦¬ìŠ¤íŠ¸ë¥¼ ë‚´ê°€ ë§Œë“  ë°ì´í„°ì…‹ í´ë˜ìŠ¤ì— ì ìš©  


```python
# ì´ë¯¸ì§€ì— ëŒ€í•œ ê²½ë¡œ, ì¼ê´„ì ìœ¼ë¡œ ì ìš©í•  ì „ì²˜ë¦¬ ì´ 2ê°€ì§€ë¥¼ ì¸ìˆ˜ë¡œ ë„£ì–´ì¤Œ.
dataset = CustomData(image_list, transform) 
# ğŸ”¥ğŸ”¥ğŸ”¥ ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ” ê²ƒì¼ê¹Œ?


dataloader = DataLoader(
    dataset=dataset,  # ğŸ”¥ğŸ”¥ğŸ”¥ ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ” ê²ƒì¼ê¹Œ?
    batch_size=25,
    shuffle=True,
    drop_last=False,  # ë§ˆì§€ë§‰ì— ë‚¨ëŠ” ë°ì´í„°ë„ ì‚¬ìš©í•©ë‹ˆë‹¤. (False: ë²„ë¦¬ì§€ ì•ŠìŒ)
)
```

### ğŸŸ¡ ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ DataLoaderì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ë°°ì¹˜ êº¼ë‚´ë³´ê¸°  
- DataLoaderì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.  


```python
dataiter = iter(dataloader) # iterate 
print(dataiter)

batch = next(dataiter)
print(batch)
```

    <torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000019EBAD965D0>
    


    ---------------------------------------------------------------------------

    PermissionError                           Traceback (most recent call last)

    Cell In[63], line 4
          1 dataiter = iter(dataloader) # iterate 
          2 print(dataiter)
    ----> 4 batch = next(dataiter)
          5 print(batch)
    

    File c:\Users\bb\Desktop\learn_deeplearning\.venv\Lib\site-packages\torch\utils\data\dataloader.py:734, in _BaseDataLoaderIter.__next__(self)
        731 if self._sampler_iter is None:
        732     # TODO(https://github.com/pytorch/pytorch/issues/76750)
        733     self._reset()  # type: ignore[call-arg]
    --> 734 data = self._next_data()
        735 self._num_yielded += 1
        736 if (
        737     self._dataset_kind == _DatasetKind.Iterable
        738     and self._IterableDataset_len_called is not None
        739     and self._num_yielded > self._IterableDataset_len_called
        740 ):
    

    File c:\Users\bb\Desktop\learn_deeplearning\.venv\Lib\site-packages\torch\utils\data\dataloader.py:790, in _SingleProcessDataLoaderIter._next_data(self)
        788 def _next_data(self):
        789     index = self._next_index()  # may raise StopIteration
    --> 790     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
        791     if self._pin_memory:
        792         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)
    

    File c:\Users\bb\Desktop\learn_deeplearning\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py:52, in _MapDatasetFetcher.fetch(self, possibly_batched_index)
         50         data = self.dataset.__getitems__(possibly_batched_index)
         51     else:
    ---> 52         data = [self.dataset[idx] for idx in possibly_batched_index]
         53 else:
         54     data = self.dataset[possibly_batched_index]
    

    File c:\Users\bb\Desktop\learn_deeplearning\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py:52, in <listcomp>(.0)
         50         data = self.dataset.__getitems__(possibly_batched_index)
         51     else:
    ---> 52         data = [self.dataset[idx] for idx in possibly_batched_index]
         53 else:
         54     data = self.dataset[possibly_batched_index]
    

    Cell In[58], line 26, in CustomData.__getitem__(self, idx)
         22 image = self.image_path[idx]
         23 # image ë³€ìˆ˜ëŠ” 'íŒŒì¼ ê²½ë¡œ ë¬¸ìì—´'ì…ë‹ˆë‹¤. ì£¼ì„ê³¼ í˜¼ë™í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤(ì´ë¯¸ì§€ê°€ ì•„ë‹˜).
         24 # ì˜ˆ: image == "data/img_001.jpg"
    ---> 26 image = Image.open(image)  # í•´ë‹¹ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ë¥¼ ì½ì–´ ì˜´
         27 # PIL.Image.openì€ íŒŒì¼ í•¸ë“¤ì„ ì—° ìƒíƒœë¡œ ë°˜í™˜(ì§€ì—° ë¡œë”©)í•©ë‹ˆë‹¤.
         28 # íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë‹«ìœ¼ë ¤ë©´ with Image.open(path) as img: ê°™ì€ ë¬¸ë²•ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
         29 # ë˜í•œ, ì±„ë„ í†µì¼ì„ ìœ„í•´ .convert('RGB') í˜¹ì€ .convert('L')ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
         31 if self.transform is not None:
    

    File c:\Users\bb\Desktop\learn_deeplearning\.venv\Lib\site-packages\PIL\Image.py:3513, in open(fp, mode, formats)
       3511 if is_path(fp):
       3512     filename = os.fspath(fp)
    -> 3513     fp = builtins.open(filename, "rb")
       3514     exclusive_fp = True
       3515 else:
    

    PermissionError: [Errno 13] Permission denied: './data/safety-data/human-accident\\jam'





```python
# ë°°ì¹˜ì—ëŠ” ì´ë¯¸ì§€ì™€ ë¼ë²¨ì´ í•¨ê»˜ ë“¤ì–´ìˆìœ¼ë¯€ë¡œ, ê°ê°ì„ imagesì™€ labels ë³€ìˆ˜ì— ì €ì¥.
images, labels = batch
```


```python
# í•œ ë°°ì¹˜ì— ë“¤ì–´ìˆëŠ” ì´ë¯¸ì§€ì™€ ë¼ë²¨ì˜ ê°œìˆ˜ë¥¼ í™•ì¸. (batch_sizeì™€ ë™ì¼)
len(images), len(labels)
```


```python
# Matplotlibë¡œ ì²« ë²ˆì§¸ ë°ì´í„° ë°°ì¹˜ ì¶œë ¥
# ì´ë¯¸ì§€ê°€ ë°°ì¹˜ (N, C, H, W) í˜•íƒœë¼ê³  ê°€ì • (ì˜ˆ: N=25, C=3, H=224, W=224)
def imshow(img, title=None):
    """ì´ë¯¸ì§€ ì‹œê°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜"""
    img = img.permute(1, 2, 0)  # (C, H, W) -> (H, W, C)
    plt.imshow(img)
    if title is not None:
        plt.title(title)
    plt.axis("off")


# ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¶œë ¥
plt.figure(figsize=(10, 10))
for i in range(len(images)):
    plt.subplot(5, 5, i + 1)  # 5x5 ê·¸ë¦¬ë“œ ìƒì„± (25ê°œì˜ ì´ë¯¸ì§€)
    imshow(images[i])
    plt.title(f"Label: {labels[i].item()}")
plt.tight_layout()
plt.show()
```

ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´, DataLoaderê°€ 25ê°œì˜ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°ì´í„°(í…ì„œ í˜•íƒœ)ì™€ 25ê°œì˜ ë¼ë²¨ì„ í•˜ë‚˜ì˜ batchë¡œ ë¬¶ì–´ì„œ ë°˜í™˜í•´ì£¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì´ì œ ì´ batch ë°ì´í„°ë¥¼ ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë„£ì–´ì„œ í•™ìŠµì„ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤.  
