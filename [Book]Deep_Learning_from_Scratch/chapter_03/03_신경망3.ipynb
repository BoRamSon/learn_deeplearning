{
   "cells": [
   {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZJURQGFTtFO"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## 🟢 3.6. 손글씨 숫자 인식  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QukVP25DdqaM"
   },
   "source": [
    "**[노트]** *이번 장의 코드는 책 본문이나 깃허브 예제 소스와 살짝 다릅니다. 책에서는 로컬에 있는 MNIST 데이터셋을 불러오도록 작성되어 있으나, 여기서는 텐서플로(케라스)의 mnist 모듈을 이용하여 데이터셋을 읽어 옵니다. 큰 차이가 없도록 최대한 밑단의 코드만 수정했습니다.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0RDeGDgFwQL"
   },
   "source": [
    "***dataset/mnist.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "Dy6qUHP7U6cf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m mnist = tf.keras.datasets.mnist\n\u001b[32m      9\u001b[39m save_file = os.getcwd() + \u001b[33m\"\u001b[39m\u001b[33m/mnist.pkl\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "save_file = os.getcwd() + \"/mnist.pkl\"\n",
    "\n",
    "\n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "    # 이미지 데이터 평탄화\n",
    "    dataset[\"train_img\"] = train_images.reshape(train_images.shape[0], -1)\n",
    "    dataset[\"train_label\"] = train_labels\n",
    "    dataset[\"test_img\"] = test_images.reshape(test_images.shape[0], -1)\n",
    "    dataset[\"test_label\"] = test_labels\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def init_mnist():\n",
    "    dataset = _convert_numpy()\n",
    "    print(\"Creating pickle file ...\")\n",
    "    with open(save_file, \"wb\") as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def _change_one_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNIST 데이터셋 읽기\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
    "    one_hot_label :\n",
    "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
    "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
    "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "\n",
    "    with open(save_file, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    if normalize:\n",
    "        for key in (\"train_img\", \"test_img\"):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset[\"train_label\"] = _change_one_hot_label(dataset[\"train_label\"])\n",
    "        dataset[\"test_label\"] = _change_one_hot_label(dataset[\"test_label\"])\n",
    "\n",
    "    if not flatten:\n",
    "        for key in (\"train_img\", \"test_img\"):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset[\"train_img\"], dataset[\"train_label\"]), (\n",
    "        dataset[\"test_img\"],\n",
    "        dataset[\"test_label\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGBIQScbTwLc"
   },
   "source": [
    "### 3.6.1 MNIST 데이터셋  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "to1hTfy6TzuZ",
    "outputId": "69aa76d3-0176-40df-f7e6-0ea93045ac64"
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X8HGBeVigND"
   },
   "source": [
    "***ch03/mnist_show.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "BpWTXDsjZoHB",
    "outputId": "d76ceaf2-2e8a-4f10-cc69-af2d94418d57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)  # 5\n",
    "\n",
    "print(img.shape)  # (784,)\n",
    "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPmdwb0ykMVu"
   },
   "source": [
    "### 3.6.2 신경망의 추론 처리  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWgY3H353Tky"
   },
   "source": [
    "***common/functions.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2oIeap2ogMP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)  # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvoxx3Phl3ei"
   },
   "source": [
    "***ch03/neuralnet_mnist.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_zhULlzkRHe",
    "outputId": "7b817eee-c58f-4169-9576-8b9c4a9d5bb6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "        normalize=True, flatten=True, one_hot_label=False\n",
    "    )\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    url = \"https://github.com/WegraLee/deep-learning-from-scratch/raw/refs/heads/master/ch03/sample_weight.pkl\"\n",
    "    urllib.request.urlretrieve(url, \"sample_weight.pkl\")\n",
    "\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "    b1, b2, b3 = network[\"b1\"], network[\"b2\"], network[\"b3\"]\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)  # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USOnL91bok3H"
   },
   "source": [
    "### 3.6.3 배치 처리  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-tsffn4onYv",
    "outputId": "b2efcda2-39fb-4922-aa22-3eef3e06a509"
   },
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUh1HyuRo0cm",
    "outputId": "f9870ee2-42fb-46a3-ab64-0bf284ab7bd3"
   },
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POsMmxaho4H3",
    "outputId": "31a59718-7936-4b00-9eaa-fa767a8bebc7"
   },
   "outputs": [],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjB9dlRwo6xQ",
    "outputId": "a51cdf79-dacc-44a6-aa38-6b750cb04444"
   },
   "outputs": [],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT0Q0VQjo8hg",
    "outputId": "f4f15a1a-82fa-4de6-c4a8-5176dfe7e098"
   },
   "outputs": [],
   "source": [
    "W3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KNLEhlTpAvl"
   },
   "source": [
    "***ch03/neuralnet_mnist_batch.py***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ii_62OD1pD3i",
    "outputId": "57ea6164-39d2-41ed-e45e-ed2e72386492"
   },
   "outputs": [],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100  # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i : i + batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i : i + batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQNmsQqn3p4w",
    "outputId": "e8f319f5-1a28-4b44-fe8d-dcac16f32d0e"
   },
   "outputs": [],
   "source": [
    "list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7li9XlvE3tiZ",
    "outputId": "2dae760b-5070-404f-ed08-7659592ddeef"
   },
   "outputs": [],
   "source": [
    "list(range(0, 10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vas6pnYz3x0L",
    "outputId": "c200fae7-38dd-4ed2-f904-46e3efc7575c"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
    "y = np.argmax(x, axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dd2D3vkI4FuI",
    "outputId": "2b0185a2-6a2a-44ea-dbd6-1de3ddd9cf44"
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 2, 1, 0])\n",
    "t = np.array([1, 2, 0, 0])\n",
    "print(y == t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmA2l0Di4N8C",
    "outputId": "c31acadc-10bb-477d-9795-a5728150c717"
   },
   "outputs": [],
   "source": [
    "np.sum(y == t)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
