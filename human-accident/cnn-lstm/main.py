import os                           # íŒŒì¼/í´ë” ê²½ë¡œ ì²˜ë¦¬, ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì„ ìœ„í•´ ì‚¬ìš©
import time                         # í•™ìŠµ ì‹œê°„ ì¸¡ì •(ë¡œê·¸ ì¶œë ¥ìš©)
import argparse                     # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±
from pathlib import Path            # ê²½ë¡œ í•´ì„ ë° ì ˆëŒ€ê²½ë¡œ ë³€í™˜

import torch                            # PyTorch ê¸°ë³¸ íŒ¨í‚¤ì§€
import torch.nn as nn                   # ì‹ ê²½ë§ ë ˆì´ì–´/ì†ì‹¤í•¨ìˆ˜ ë“±
from torch.optim import Adam            # Adam ì˜µí‹°ë§ˆì´ì €
from torch.utils.data import DataLoader # ë¯¸ë‹ˆë°°ì¹˜ ë°ì´í„° ë¡œë”
from torchvision import transforms      # ì´ë¯¸ì§€ ì „ì²˜ë¦¬(transform)

from train_valid_dataset import CustomData  # ìš°ë¦¬ê°€ ë§Œë“  ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹(Train/Valid ë¶„í•  í¬í•¨)
from models.cnnlstm import CNNLSTM          # CNN + LSTM ëª¨ë¸ ì •ì˜


def get_dataloaders(root: str, batch_size: int, num_workers: int, train_ratio: float, seed: int):
    """
    CustomData ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ/ê²€ì¦ DataLoaderë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - root        : ë°ì´í„° ë£¨íŠ¸(í´ë˜ìŠ¤ í´ë”ë“¤ì´ ë°”ë¡œ í•˜ìœ„ì— ì¡´ì¬)
    - batch_size  : ë°°ì¹˜ í¬ê¸°
    - num_workers : ë°ì´í„° ë¡œë”© ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ê°œìˆ˜
    - train_ratio : train/valid ë¶„í•  ë¹„ìœ¨(0.7ì´ë©´ 70:30)
    - seed        : ë¶„í•  ì…”í”Œ ì‹œë“œ(ì¬í˜„ì„±)
    """

    # í”„ë ˆì„ ë‹¨ìœ„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸: NumPy(RGB) -> PIL -> Resize -> Tensor -> Normalize(ImageNet)
    transform = transforms.Compose([
        transforms.ToPILImage(),                 # NumPy ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        transforms.Resize((224, 224)),           # ì…ë ¥ í•´ìƒë„ í†µì¼
        transforms.ToTensor(),                   # (H,W,C)[0..255] -> (C,H,W)[0..1]
        transforms.Normalize(                    # ImageNet ì‚¬ì „í•™ìŠµ ê·œì•½ì˜ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
    ])

    # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ìƒì„±: ë‚´ë¶€ì—ì„œ í´ë˜ìŠ¤ë³„ ìŠ¤ìº” ë° 70:30 ë¶„í•  ìˆ˜í–‰
    train_ds = CustomData(root=root, transform=transform, split="train", train_ratio=train_ratio, seed=seed)
    valid_ds = CustomData(root=root, transform=transform, split="valid", train_ratio=train_ratio, seed=seed)

    # DataLoader ìƒì„±: í•™ìŠµì€ ì…”í”Œ, ê²€ì¦ì€ ì…”í”Œí•˜ì§€ ì•ŠìŒ
    train_loader = DataLoader(
        train_ds,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        drop_last=False,
        pin_memory=True,
    )
    valid_loader = DataLoader(
        valid_ds,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        drop_last=False,
        pin_memory=True,
    )
    
    return train_loader, valid_loader


def train_one_epoch(model, loader, criterion, optimizer, device):
    """
    í•œ ì—í­ ë™ì•ˆ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - model     : í•™ìŠµí•  ëª¨ë¸(CNNLSTM)
    - loader    : í•™ìŠµ DataLoader
    - criterion : ì†ì‹¤í•¨ìˆ˜(CrossEntropyLoss)
    - optimizer : ìµœì í™”ê¸°(Adam)
    - device    : 'cuda' ë˜ëŠ” 'cpu'
    ë°˜í™˜: (ì—í­ í‰ê·  ì†ì‹¤, ì—í­ í‰ê·  ì •í™•ë„)
    """
    model.train()                # í•™ìŠµ ëª¨ë“œ
    running_loss = 0.0           # ì†ì‹¤ í•©ê³„(í‰ê·  ê³„ì‚°ìš©)
    running_acc = 0.0            # ì •ë‹µ ê°œìˆ˜ í•©ê³„(ì •í™•ë„ ê³„ì‚°ìš©)
    total = 0                    # ìƒ˜í”Œ ìˆ˜ í•©ê³„

    for x, y in loader:          # ë¯¸ë‹ˆë°°ì¹˜ ë°˜ë³µ: x=(B,T,C,H,W), y=(B,)
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        optimizer.zero_grad()     # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
        logits = model(x)         # ìˆœì „íŒŒ -> (B, num_classes)
        loss = criterion(logits, y)  # ì†ì‹¤ ê³„ì‚°
        loss.backward()           # ì—­ì „íŒŒ
        optimizer.step()          # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        bs = x.size(0)                            # í˜„ì¬ ë°°ì¹˜ í¬ê¸°
        running_loss += loss.item() * bs          # ê°€ì¤‘ í•©(í‰ê· ìš©)
        preds = logits.argmax(dim=1)              # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        running_acc += (preds == y).sum().item()  # ì •ë‹µ ê°œìˆ˜ ëˆ„ì 
        total += bs

    # ì „ì²´ ìƒ˜í”Œ ëŒ€ë¹„ í‰ê·  ì†ì‹¤/ì •í™•ë„
    return (running_loss / total) if total else 0.0, (running_acc / total) if total else 0.0


def validate(model, loader, criterion, device):
    """
    ê²€ì¦(Validation) 1 ì—í­ ìˆ˜í–‰(ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸ ì—†ì´ í‰ê°€ë§Œ).
    ë°˜í™˜: (ì—í­ í‰ê·  ì†ì‹¤, ì—í­ í‰ê·  ì •í™•ë„)
    """
    model.eval()                 # í‰ê°€ ëª¨ë“œ
    running_loss = 0.0
    running_acc = 0.0
    total = 0
    with torch.no_grad():        # ì¶”ë¡ ë§Œ ìˆ˜í–‰(ë©”ëª¨ë¦¬/ì—°ì‚° ì ˆì•½)
        for x, y in loader:
            x = x.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True)
            logits = model(x)
            loss = criterion(logits, y)
            bs = x.size(0)
            running_loss += loss.item() * bs
            preds = logits.argmax(dim=1)
            running_acc += (preds == y).sum().item()
            total += bs
    return (running_loss / total) if total else 0.0, (running_acc / total) if total else 0.0


def main():
    # ---------------------------------------------------------------------------
    """ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¥¼ ë°›ì•„ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. main()ì— ë§¤ê°œë³€ìˆ˜ë¥¼ ì£¼ëŠ” ëŠë‚Œì…ë‹ˆë‹¤."""
    parser = argparse.ArgumentParser(description="CustomData + CNNLSTM simple training entry")
    # ë°ì´í„° ê²½ë¡œ/í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¸ì ì •ì˜
    parser.add_argument("--root", type=str, default=os.path.join("..", "data", "safety-data", "human-accident"))
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--batch-size", type=int, default=8)
    parser.add_argument("--lr", type=float, default=1e-4)
    parser.add_argument("--weight-decay", type=float, default=1e-4)
    parser.add_argument("--num-workers", type=int, default=2)
    parser.add_argument("--save-dir", type=str, default="snapshots")
    parser.add_argument("--train-ratio", type=float, default=0.7)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--num-classes", type=int, default=6)
    # (ì˜µì…˜) ê°„ë‹¨ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ í”Œë˜ê·¸
    parser.add_argument("--use-scheduler", action="store_true")
    parser.add_argument("--lr-patience", type=int, default=3)
    parser.add_argument("--lr-factor", type=float, default=0.5)
    args = parser.parse_args()

    # ---------------------------------------------------------------------------
    os.makedirs(args.save_dir, exist_ok=True)        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ í´ë” ìƒì„±

    # ---------------------------------------------------------------------------
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")                        # ì‚¬ìš© ë””ë°”ì´ìŠ¤ ì¶œë ¥

    # ---------------------------------------------------------------------------
    # ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ ì—¬ê¸°ì„œ root pathë¥¼ ì§€ì •í•´ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
    # --root ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ í•´ì„í•˜ì—¬ í˜¼ë™ ë°©ì§€
    root_path = Path(args.root)
    if not root_path.is_absolute():
        root_path = (Path.cwd() / root_path).resolve()
    print(f"Resolved dataset root: {root_path}")

    if not root_path.exists():
        print(f"[ì˜¤ë¥˜] --root ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {root_path}")
        print("ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜, ì˜¬ë°”ë¥¸ ì ˆëŒ€/ìƒëŒ€ ê²½ë¡œë¡œ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # ---------------------------------------------------------------------------
    # ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¡œë” ì¤€ë¹„
    train_loader, valid_loader = get_dataloaders(
        root=str(root_path),
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        train_ratio=args.train_ratio,
        seed=args.seed,
    )
    print(f"Train samples: {len(train_loader.dataset)}, Valid samples: {len(valid_loader.dataset)}")

    # ---------------------------------------------------------------------------
    # ëª¨ë¸/ì†ì‹¤/ì˜µí‹°ë§ˆì´ì € ì •ì˜
    model = CNNLSTM(num_classes=args.num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    # ---------------------------------------------------------------------------
    # (ì˜µì…˜) ReduceLROnPlateau ìŠ¤ì¼€ì¤„ëŸ¬: ê²€ì¦ ì†ì‹¤(val_loss)ì´ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ LR ê°ì†Œ
    scheduler = None
    if args.use_scheduler:
        from torch.optim.lr_scheduler import ReduceLROnPlateau
        scheduler = ReduceLROnPlateau(
            optimizer, mode="min", factor=args.lr_factor, patience=args.lr_patience, verbose=True
        )

    # ---------------------------------------------------------------------------
    # ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ í•™ìŠµ ë£¨í”„
    best_val_acc = 0.0
    for epoch in range(1, args.epochs + 1):
        t0 = time.time()

        # =========================================================================================================
        # ì²« ë°°ì¹˜ì—ì„œ GPU ì‚¬ìš© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ë””ë²„ê·¸ ì¶œë ¥
        printed_gpu_info = False

        def _train_one_epoch_with_debug(model, loader, criterion, optimizer, device):
            nonlocal printed_gpu_info
            model.train()
            running_loss = 0.0
            running_acc = 0.0
            total = 0
            for x, y in loader:
                x = x.to(device, non_blocking=True)
                y = y.to(device, non_blocking=True)

                if not printed_gpu_info:
                    try:
                        model_device = next(model.parameters()).device
                        resnet_dev = model.resnet.fc[0].weight.device if hasattr(model.resnet, 'fc') else model_device
                        lstm_dev = model.lstm.weight_ih_l0.device
                        print("[ë””ë²„ê·¸] ì…ë ¥ x.device:", x.device)
                        print("[ë””ë²„ê·¸] ëª¨ë¸ íŒŒë¼ë¯¸í„° device:", model_device)
                        print("[ë””ë²„ê·¸] ResNet fc device:", resnet_dev)
                        print("[ë””ë²„ê·¸] LSTM device:", lstm_dev)
                        if torch.cuda.is_available():
                            print("[ë””ë²„ê·¸] CUDA name:", torch.cuda.get_device_name(0))
                            print("[ë””ë²„ê·¸] CUDA memory allocated (MB):", round(torch.cuda.memory_allocated() / (1024**2), 2))
                    except Exception as e:
                        print(f"[ë””ë²„ê·¸] ë””ë°”ì´ìŠ¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
                    printed_gpu_info = True

                optimizer.zero_grad()
                logits = model(x)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()

                bs = x.size(0)
                running_loss += loss.item() * bs
                preds = logits.argmax(dim=1)
                running_acc += (preds == y).sum().item()
                total += bs

            return (running_loss / total) if total else 0.0, (running_acc / total) if total else 0.0

        train_loss, train_acc = _train_one_epoch_with_debug(model, train_loader, criterion, optimizer, device)
        # =========================================================================================================

        val_loss, val_acc = validate(model, valid_loader, criterion, device)
        took = time.time() - t0

        # ì§„í–‰ ìƒí™© ë¡œê·¸
        print(
            f"[Epoch {epoch}/{args.epochs}] "
            f"train_loss={train_loss:.4f} train_acc={train_acc*100:.2f}% | "
            f"val_loss={val_loss:.4f} val_acc={val_acc*100:.2f}% | "
            f"time={took:.1f}s"
        )

        if scheduler is not None:
            scheduler.step(val_loss)  # ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ë³´í†µ ê²€ì¦ ì§€í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë™ì‘

        # ë§¤ ì—í­ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        ckpt = {
            "epoch": epoch,
            "state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "num_classes": args.num_classes,
        }
        ckpt_path = os.path.join(args.save_dir, f"CNNLSTM-epoch{epoch}-valacc{val_acc:.4f}.pth")
        torch.save(ckpt, ckpt_path)

        # ìµœê³  ì„±ëŠ¥(best) ëª¨ë¸ ê°±ì‹ 
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(ckpt, os.path.join(args.save_dir, "best.pth"))


if __name__ == "__main__":
    main()  # ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ í•™ìŠµ ì‹œì‘
