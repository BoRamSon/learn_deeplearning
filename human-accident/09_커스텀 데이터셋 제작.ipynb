{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33310fc9-2465-421f-a55d-19453a1b28d4",
   "metadata": {},
   "source": [
    "# 🟩 1. 커스텀 데이터셋 제작         \n",
    "\n",
    "https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html  \n",
    "\n",
    "\n",
    "- 데이터로더(필수 내용)     \n",
    "- 각 훈련별로 '어떻게 훈련 되고 있는가?' -> wandb, comet.ml(정확도, loss 그래프 출력)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e90f48-8097-4443-823d-a408fbf1e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #훈련\n",
    "from torch.utils.data import Dataset, DataLoader #커스텀 데이터셋을 만들기 위함\n",
    "\n",
    "import os #로컬 컴퓨터에서 데이터셋을 불러오기 위해\n",
    "import cv2 # 시각화 해서 표현하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "519c53b9-7544-4e3e-88e6-bad912fa84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __함수__ : 던더 함수\n",
    "class SimpleDataset(Dataset):\n",
    "    #이 클래스의 객체가 생성되면 무조건 __init__ 함수가 동작하게 됨\n",
    "    #기초 데이터, 함수 동작하도록 연결\n",
    "    def __init__(self, t):\n",
    "        self.t = t\n",
    "\n",
    "    #데이터셋의 길이 반환\n",
    "    #파이토치가 훈련을 할 때 len() -> 배치사이즈 대비 얼마나 데이터셋이 남아있는 지 체크할 때 씀\n",
    "    def __len__(self):\n",
    "        return self.t\n",
    "\n",
    "    #데이터 + 라벨 -> 한 쌍을 뽑는 데 씀\n",
    "    #idx(index) = 몇 번째 데이터? \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor([idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912551d8-bf89-4682-ad71-faa158c4409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(t=7)\n",
    "\n",
    "\n",
    "#이 데이터셋을 훈련에서 어떻게 활용할 것인가? \n",
    "dataloader = DataLoader(dataset = dataset ,   #어떤 데이터셋을 훈련에 쓸 거니?\n",
    "                        batch_size = 2, #데이터셋을 쪼개 배치로 만듦\n",
    "                        shuffle = True,    #데이터셋을 섞어주는(랜덤)\n",
    "                        drop_last = True)  #배치사이즈 만들고 남은 데이터 쓸거야?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94d3967-dd95-49a3-b159-0db49c5b75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "tensor([[6],\n",
      "        [3]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[5],\n",
      "        [2]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0],\n",
      "        [1]])\n",
      "<class 'torch.Tensor'>\n",
      "epoch : 1\n",
      "tensor([[3],\n",
      "        [6]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[4],\n",
      "        [1]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[2],\n",
      "        [0]])\n",
      "<class 'torch.Tensor'>\n",
      "epoch : 2\n",
      "tensor([[5],\n",
      "        [2]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1],\n",
      "        [6]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[4],\n",
      "        [3]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for e in range(3):\n",
    "    print(f\"epoch : {e}\")\n",
    "\n",
    "    for batch in dataloader:\n",
    "        print(batch)\n",
    "        print(type(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fa8fb-192e-4a7b-837f-3c782be44030",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 🟢 이미지 데이터셋을 커스텀화 함          \n",
    "\n",
    "- 이미지(0~255) 숫자로 이루어진 데이터 -> 딥러닝 -> 텐서 형태로 표현  \n",
    "- 텐서 형태로 이미지를 표현해 줘야 함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1c572-13ea-460a-9026-2028c71690dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision: PyTorch에서 이미지 처리/데이터셋 관련 기능을 제공하는 라이브러리\n",
    "# transforms: 이미지를 딥러닝 학습에 적합한 형태로 바꿔주는 기능 모음 (자르기, 회전, 텐서 변환, 정규화 등)\n",
    "# torchvision -> 딥러닝(이미지) 수행하는 클래스 이름 #transform 이미지를 조절\n",
    "from torchvision import transforms  \n",
    "\n",
    "from PIL import Image # -> 이미지를 표현할 수 있는 파이썬 라이브러리 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d90c61-3e1f-4b0b-814d-2647f817c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.image_path = path  # 전체 이미지 경로를 저장\n",
    "        # self.image_path는 보통 문자열 경로들의 리스트(예: [\"data/a.jpg\",\"data/b.jpg\", ...])\n",
    "        # 또는 pathlib.Path 객체들의 리스트로 기대됩니다. \"path\"라는 이름 때문에 폴더 경로 하나를 받을 것처럼 보일 수 있으니\n",
    "        # 실제로는 '파일 경로 리스트'인지 '폴더 경로(내부 탐색 필요)'인지 명확히 해야 합니다.\n",
    "        \n",
    "        self.transform = transform  # 이미지에 대해 일괄적으로 적용할 '전처리'\n",
    "        # transform은 callable (예: torchvision.transforms.Compose([...]))이어야 하며,\n",
    "        # 입력으로 PIL.Image을 받고 출력으로 torch.Tensor(또는 변환된 PIL/ndarray)를 반환하는 것이 일반적입니다.\n",
    "\n",
    "    def __len__(self):\n",
    "        # if (이미지수 == 라벨수) return 이미지 수\n",
    "        return len(self.image_path)\n",
    "        # __len__은 DataLoader가 전체 데이터 개수를 알기 위해 호출합니다.\n",
    "        # image_path가 리스트가 아니라면(예: glob 결과가 빈 경우) 여기서 에러 또는 0을 반환할 수 있습니다.\n",
    "\n",
    "    # 텐서 형태로 변환된 이미지를 돌려줌\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_path[idx]\n",
    "        # image 변수는 '파일 경로 문자열'입니다. 주석과 혼동하면 안 됩니다(이미지가 아님).\n",
    "        # 예: image == \"data/img_001.jpg\"\n",
    "\n",
    "        image = Image.open(image)  # 해당 경로에서 이미지를 읽어 옴\n",
    "        # PIL.Image.open은 파일 핸들을 연 상태로 반환(지연 로딩)합니다.\n",
    "        # 파일을 안전하게 닫으려면 with Image.open(path) as img: 같은 문법을 권장합니다.\n",
    "        # 또한, 채널 통일을 위해 .convert('RGB') 혹은 .convert('L')을 호출하는 것이 안전합니다.\n",
    "\n",
    "        if self.transform is not None:\n",
    "            result = self.transform(image)\n",
    "            # transform이 ToTensor 등을 포함하면 result는 torch.Tensor (C,H,W), dtype=float32, 값범위 0~1 이 됩니다.\n",
    "            # 주의: transform이 PIL 이미지를 변경하고 닫지 않으므로 이미지 리소스 관리를 신경 써야 합니다.\n",
    "\n",
    "        # csv,파일 이름 등을 이용해서 데이터에 맞는 라벨을 반환\n",
    "        label = 1\n",
    "        # 현재는 하드코딩된 더미 라벨(1)입니다. 실제 작업에서는:\n",
    "        # - 파일명/폴더 구조에서 라벨을 파싱하거나,\n",
    "        # - __init__에 labels 리스트/딕셔너리를 전달하거나,\n",
    "        # - CSV 파일을 읽어 라벨 맵을 만들어 사용해야 합니다.\n",
    "        # 라벨은 정수(int) 또는 torch.Tensor (예: torch.tensor(label, dtype=torch.long)) 로 반환하는 것이 일반적입니다.\n",
    "\n",
    "        return result, label\n",
    "        # 주의: 만약 self.transform이 None이면 result 변수가 정의되지 않아 NameError가 납니다.\n",
    "        # 따라서 transform None 케이스를 반드시 처리해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81213a9a-3c33-4716-aa70-27dd0f6d7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #전처리의 다양한 종류를 여기서 적용해준다.\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9facaa3-5884-4f68-be87-f2fa10483433",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mimage_list\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'image_list' is not defined"
     ]
    }
   ],
   "source": [
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d9c60d-9ea2-4cf6-9eb9-55d50f45e009",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/jeong/Desktop/영등포/11.16 커스텀 데이터셋/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m origin = \u001b[33m'\u001b[39m\u001b[33mC:/Users/jeong/Desktop/영등포/11.16 커스텀 데이터셋/train/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m image_list = [os.path.join(origin, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/jeong/Desktop/영등포/11.16 커스텀 데이터셋/train/'"
     ]
    }
   ],
   "source": [
    "origin = 'C:/Users/jeong/Desktop/영등포/11.16 커스텀 데이터셋/train/'\n",
    "image_list = [os.path.join(origin, x) for x in os.listdir(origin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669191e-9ac1-447c-a697-451aa12b9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = 'C:/Users/jeong/Desktop/영등포/11.16 커스텀 데이터셋/train/'\n",
    "os.listdir(origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710660b-a4ae-4f1e-89e7-d67fede046f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 🟢 이미지리스트를 내가 만든 데이터셋 클래스에 적용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344353a6-9a3a-4c16-93ad-9238543b867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomData(image_list, transform) #이미지에 대한 경로, 일괄적으로 적용할 전처리\n",
    "dataloader = DataLoader(dataset = dataset,\n",
    "                        batch_size = 25,\n",
    "                        shuffle = True,\n",
    "                        drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100ad6bc-d298-4b59-b1de-99f4ea6af71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000015AEAB38910>\n",
      "tensor([[2],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader) # iterate \n",
    "print(dataiter)\n",
    "\n",
    "batch = next(dataiter)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa4057-6894-44cf-a8b2-58a446b43e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d22a0-819e-4731-a68f-5ac68804c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da3364-eaad-459b-aa93-9560d1c2575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib로 첫 번째 데이터 배치 출력\n",
    "# 이미지가 배치 (N, C, H, W) 형태라고 가정 (예: N=25, C=3, H=224, W=224)\n",
    "def imshow(img, title=None):\n",
    "    \"\"\"이미지 시각화를 위한 함수\"\"\"\n",
    "    img = img.permute(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# 배치의 첫 번째 이미지 출력\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(5, 5, i + 1)  # 5x5 그리드 생성 (25개의 이미지)\n",
    "    imshow(images[i])\n",
    "    plt.title(f\"Label: {labels[i].item()}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69ca70-2db5-4458-ab62-c0121c211818",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f92f6d-7c12-4ff1-a0ad-19e577a0f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff393-4dbc-4552-8183-f2e132d7f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"poth_resnet2\",  # 프로젝트 이름\n",
    "    #config.yaml\n",
    "    config={\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 25,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"model\": \"ResNet18\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b237961-98f7-403d-8bb4-14de61def7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 모델 정의\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = 2  # 데이터셋의 클래스 개수에 맞게 설정\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# GPU 사용 여부\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 훈련\n",
    "num_epochs = wandb.config.epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)  # 데이터 GPU로 이동\n",
    "\n",
    "        optimizer.zero_grad()  # 옵티마이저 초기화\n",
    "        outputs = model(images)  # 순전파\n",
    "        loss = criterion(outputs, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # **WandB 배치 로깅**\n",
    "        wandb.log({\"batch_loss\": loss.item()})\n",
    "\n",
    "    # 에포크 종료 시 평균 손실 로그 기록\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    wandb.log({\"epoch_loss\": avg_loss, \"epoch\": epoch + 1})\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 모델 저장 (선택 사항)\n",
    "torch.save(model.state_dict(), \"resnet18_poth_dataset.pth\")\n",
    "wandb.save(\"resnet18_poth_dataset.pth\")\n",
    "print(\"Model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
