# 제조업 안전사고 예방을 위한 AI 영상 분석 시스템 개발  

**부제:** CNN-LSTM 모델을 활용한 작업자 이상 행동 탐지  

**발표자:** OOO  
**소속:** OOO  
**날짜:** 2024.MM.DD  

---

## 1. 서론: 프로젝트 개요  

### 1.1. 문제 제기 및 필요성  

-   **문제점:** 제조업 현장에서 발생하는 넘어짐, 충돌 등의 안전사고는 인명 피해와 생산성 저하를 유발하는 심각한 문제입니다.  
-   **기존 시스템의 한계:** 전통적인 CCTV 관제 시스템은 관제 인력의 피로도와 집중력 저하로 인해 실시간 대응에 한계가 있으며, 대부분 사고 발생 후 원인 분석에 사용됩니다.  

### 1.2. 프로젝트 목표  

-   컴퓨터 비전 기술을 활용하여 작업자의 **위험 행동(이상 행동)을 실시간으로 자동 탐지**하는 AI 시스템을 개발합니다.  
-   사고 발생 시 즉각적인 알림을 통해 **사전 예방 및 신속한 초기 대응**이 가능한 체계를 구축하는 것을 목표로 합니다.  

### 1.3. 기대 효과  

-   안전사고 발생률 감소 및 중대재해 예방  
-   안전 관리 효율성 증대 및 비용 절감  
-   데이터 기반의 안전한 작업 환경 조성  

---

## 2. 데이터셋 소개  

### 2.1. 원본 데이터  

-   **데이터 출처:** AI Hub - 스마트 제조 시설 안전 감시를 위한 데이터  
-   **데이터 구성:**  
    -   **클래스(Class):** `넘어짐`, `충돌`, `끼임` 등 총 6개의 작업자 행동 클래스로 구성  
    -   **데이터 형태:** 각 행동이 촬영된 원본 비디오 파일 (`.mp4`, `.avi`)  

### 2.2. 데이터 전처리  

-   **목표:** 원본 비디오 데이터를 학습 모델의 입력 형식에 맞게 가공합니다.  
-   **과정:**  
    1.  **프레임 추출:** 각 비디오를 프레임 단위의 이미지(`.jpg`)로 변환하여 저장합니다.  
    2.  **데이터 분할:** 전체 데이터셋을 **학습(Training) 70%**, **검증(Validation) 30%** 비율로 분할하여 모델의 일반화 성능을 객관적으로 평가할 수 있도록 준비합니다.  

---

## 3. 모델 아키텍처: CNN-LSTM  

### 3.1. 모델 선정 이유  

영상 데이터는 **공간적 정보(Spatial Feature)**와 **시간적 정보(Temporal Feature)**를 모두 포함하고 있습니다. 이 두 가지 특징을 효과적으로 학습하기 위해 CNN과 LSTM을 결합한 모델을 선정했습니다.  

-   **CNN (ResNet-101):** 비디오의 각 프레임에서 **공간적 특징**을 추출합니다.  
    -   *역할: "프레임 안에 무엇이 있는가?" (객체, 배경, 자세 등)*  
-   **LSTM:** CNN이 추출한 프레임별 특징들의 **시간적 순서**를 학습합니다.  
    -   *역할: "프레임들이 어떻게 변하는가?" (움직임, 행동의 연속성 등)*  

### 3.2. 모델 구조  

!CNN-LSTM Architecture  
*<p align="center">그림 1: CNN-LSTM 모델 구조도 (출처: pranoyr/cnn-lstm)</p>*  

1.  **입력:** 비디오에서 샘플링된 프레임 시퀀스 (예: 16 프레임)  
2.  **CNN (Feature Extractor):** 각 프레임이 사전 학습된 ResNet-101을 통과하여 고차원 특징 벡터로 변환됩니다.  
3.  **LSTM (Sequence Learning):** 프레임 특징 벡터 시퀀스가 LSTM 레이어를 통과하며 행동의 동적인 문맥을 학습합니다.  
4.  **분류 (Classifier):** LSTM의 최종 출력이 Fully Connected Layer를 거쳐 최종 행동 클래스로 분류됩니다.  

---

## 4. 개발 및 학습 과정  

### 4.1. 개발 환경  

-   **H/W:** Apple M1 Pro  
-   **S/W:**  
    -   Python 3.11  
    -   PyTorch (MPS 가속 활용)  
    -   `uv` 패키지 관리자  
    -   OpenCV, NumPy 등  

### 4.2. 데이터 로더 구현  

-   AI Hub 데이터를 모델 학습에 맞게 공급하기 위해 PyTorch의 `Dataset`과 `DataLoader`를 상속받는 `CustomData` 클래스와 로더 함수를 직접 구현했습니다.  
-   이 과정에서 학습/검증 데이터 분할, 프레임 로딩, 전처리 파이프라인 적용 등의 로직을 포함시켰습니다.  

### 4.3. 학습 파이프라인  

-   **하이퍼파라미터:**  
    | 파라미터 | 값 | 설명 |  
    | :--- | :--- | :--- |
    | Epochs | 50 | 전체 데이터셋 반복 학습 횟수 |  
    | Batch Size | 8 | 한 번에 학습할 데이터 샘플 수 |  
    | Learning Rate | 1e-4 | 학습률 |  
    | Optimizer | Adam | 최적화 알고리즘 |  
    | Loss Function | CrossEntropyLoss | 다중 클래스 분류 손실 함수 |  
-   **실행:** `main.py` 스크립트를 통해 커맨드라인 인자로 하이퍼파라미터를 설정하여 학습을 진행했습니다.  

---

## 5. 학습 결과 및 분석  

### 5.1. 학습 곡선 (Training & Validation Curve)  

TensorBoard를 통해 시각화된 학습 과정의 손실(Loss) 및 정확도(Accuracy) 그래프입니다.  

*(여기에 TensorBoard에서 캡처한 Loss 및 Accuracy 그래프 이미지를 삽입하세요)*  

-   **손실(Loss):** Epoch가 진행됨에 따라 학습 및 검증 손실이 안정적으로 감소하는 것을 확인했습니다.  
-   **정확도(Accuracy):** 학습 정확도와 함께 검증 정확도 또한 꾸준히 상승하여 모델이 과적합되지 않고 잘 일반화되고 있음을 보여줍니다.  

### 5.2. 최종 성능  

-   **최종 검증 정확도(Validation Accuracy):** **XX.XX %**  
-   가장 높은 검증 정확도를 보인 모델을 `best.pth`로 저장하여 최적의 성능을 확보했습니다.  

---

## 6. 결론 및 향후 계획  

### 6.1. 결론  

-   AI Hub의 스마트 제조 데이터를 활용하고, CNN-LSTM 모델을 성공적으로 학습시켜 **제조업 작업자의 이상 행동을 탐지하는 AI 모델 개발**을 완료했습니다.  
-   최종 검증 정확도 **XX.XX%**를 달성하여 본 시스템의 현장 적용 가능성을 확인했습니다.  

### 6.2. 향후 계획  

1.  **학습 속도 개선:**  
    -   **문제:** 현재 실시간으로 비디오를 디코딩하여 학습 속도에 병목 현상이 발생합니다.  
    -   **개선:** 모든 비디오를 프레임 이미지로 **사전 변환**하는 전처리 파이프라인을 도입하여 학습 효율을 극대화할 계획입니다.  
2.  **실시간 추론 시스템 구축:**  
    -   학습된 `best.pth` 모델을 사용하여 실제 CCTV 스트림이나 비디오 파일에 대해 실시간으로 이상 행동을 탐지하고 알림을 주는 **추론(Inference) 시스템**을 개발합니다.  
3.  **모델 성능 고도화:**  
    -   더 다양한 데이터 증강(Augmentation) 기법을 적용하여 모델의 강건성(Robustness)을 향상시킵니다.  
    -   필요시 모델 경량화를 통해 임베디드 환경에서의 구동 가능성을 모색합니다.  

---

## 7. Q & A  

**감사합니다.**  